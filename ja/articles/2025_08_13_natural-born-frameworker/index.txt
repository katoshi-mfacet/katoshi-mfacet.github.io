1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
4:I[6874,["937","static/chunks/app/%5Blang%5D/articles/%5Bslug%5D/page-70e369dc1af8e3b1.js"],""]
7:I[9665,[],"OutletBoundary"]
9:I[4911,[],"AsyncMetadataOutlet"]
b:I[9665,[],"ViewportBoundary"]
d:I[9665,[],"MetadataBoundary"]
e:"$Sreact.suspense"
10:I[8393,[],""]
:HL["/_next/static/media/569ce4b8f30dc480-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/8478701d0f9a9ae4.css","style"]
0:{"P":null,"b":"s5IqROsnKAG8H9czwwk9O","p":"","c":["","ja","articles","2025_08_13_natural-born-frameworker",""],"i":false,"f":[[["",{"children":[["lang","ja","d"],{"children":["articles",{"children":[["slug","2025_08_13_natural-born-frameworker","d"],{"children":["__PAGE__",{}]}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/8478701d0f9a9ae4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"ja","children":["$","body",null,{"className":"__variable_5cfdac __variable_9a8899 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen bg-gray-50 flex flex-col justify-center py-12 sm:px-6 lg:px-8","children":["$","div",null,{"className":"sm:mx-auto sm:w-full sm:max-w-md","children":["$","div",null,{"className":"text-center","children":[["$","h1",null,{"className":"text-9xl font-bold text-gray-300","children":"404"}],["$","h2",null,{"className":"mt-4 text-3xl font-bold text-gray-900","children":"ページが見つかりません"}],["$","p",null,{"className":"mt-4 text-lg text-gray-600","children":"お探しのページは存在しないか、移動された可能性があります。"}],["$","div",null,{"className":"mt-8","children":["$","$L4",null,{"href":"/ja","className":"inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 transition-colors","children":"ホームに戻る"}]}]]}]}]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":[["lang","ja","d"],["$","$1","c",{"children":[null,"$L5"]}],{"children":["articles",["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","2025_08_13_natural-born-frameworker","d"],["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":["$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},[["$","div","l",{"className":"min-h-screen bg-gray-50 flex items-center justify-center","children":["$","div",null,{"className":"animate-spin rounded-full h-12 w-12 border-b-2 border-blue-600"}]}],[],[]],false],["$","$1","h",{"children":[null,[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Ld",null,{"children":["$","div",null,{"hidden":true,"children":["$","$e",null,{"fallback":null,"children":"$Lf"}]}]}]]}],false]],"m":"$undefined","G":["$10",[]],"s":false,"S":true}
5:["$","div",null,{"children":[["$","header",null,{"className":"bg-white shadow-sm","children":["$","div",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"flex justify-between items-center py-4","children":[["$","div",null,{"className":"flex items-center space-x-8","children":[["$","$L4",null,{"href":"/ja","className":"text-xl font-bold text-gray-900 hover:text-blue-600","children":"katoshiの研究ノート"}],["$","nav",null,{"className":"hidden md:flex space-x-6","children":[["$","$L4",null,{"href":"/ja/articles","className":"text-gray-600 hover:text-gray-900 font-medium","children":"記事一覧"}],["$","$L4",null,{"href":"/ja/categories","className":"text-gray-600 hover:text-gray-900 font-medium","children":"カテゴリ"}],["$","$L4",null,{"href":"/ja/archive","className":"text-gray-600 hover:text-gray-900 font-medium","children":"アーカイブ"}],["$","$L4",null,{"href":"/ja/vocabulary","className":"text-gray-600 hover:text-gray-900 font-medium","children":"用語集"}],["$","$L4",null,{"href":"/ja/about","className":"text-gray-600 hover:text-gray-900 font-medium","children":"About"}]]}]]}],["$","div",null,{"className":"flex items-center space-x-4","children":[["$","div",null,{"className":"flex items-center space-x-3","role":"list","children":[["$","a","X (Twitter)",{"href":"https://twitter.com/katoshi_mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"X (Twitter)","aria-label":"Xアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"}]}]}],["$","a","Note",{"href":"https://note.com/katoshi_mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"Note","aria-label":"Noteアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-1 16H6V5h12v14zM8 7h8v2H8V7zm0 4h8v2H8v-2zm0 4h5v2H8v-2z"}]}]}],["$","a","YouTube",{"href":"https://www.youtube.com/channel/UCRZjsc8pWWT8GQLBA6gc2MQ","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"YouTube","aria-label":"YouTubeチャンネルを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"}]}]}],["$","a","Medium",{"href":"https://medium.com/@katoshi-mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"Medium","aria-label":"Mediumアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M13.54 12a6.8 6.8 0 01-6.77 6.82A6.8 6.8 0 010 12a6.8 6.8 0 016.77-6.82A6.8 6.8 0 0113.54 12zM20.96 12c0 3.54-1.51 6.42-3.38 6.42-1.87 0-3.39-2.88-3.39-6.42s1.52-6.42 3.39-6.42 3.38 2.88 3.38 6.42M24 12c0 3.17-.53 5.75-1.19 5.75-.66 0-1.19-2.58-1.19-5.75s.53-5.75 1.19-5.75C23.47 6.25 24 8.83 24 12z"}]}]}]]}],"$L11"]}]]}]}]}],"$L12"]}]
11:["$","div",null,{"className":"flex gap-2 items-center","children":[["$","span",null,{"className":"text-sm text-gray-600","children":"Language:"}],[["$","a","ja",{"href":"/ja/","className":"px-2 py-1 text-sm rounded bg-blue-500 text-white","children":"日本語"}]]]}]
12:["$","main",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]}]
13:T456,prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h1:text-3xl prose-h1:mb-6 prose-h1:mt-8 prose-h1:border-b prose-h1:border-gray-200 prose-h1:pb-2 prose-h2:text-2xl prose-h2:mb-4 prose-h2:mt-8 prose-h2:border-b prose-h2:border-gray-100 prose-h2:pb-2 prose-h3:text-xl prose-h3:mb-3 prose-h3:mt-6 prose-h4:text-lg prose-h4:mb-2 prose-h4:mt-4 prose-p:text-lg prose-p:leading-relaxed prose-p:text-gray-800 prose-a:text-blue-600 prose-a:hover:text-blue-800 prose-a:underline prose-strong:text-gray-900 prose-strong:font-semibold prose-em:text-gray-700 prose-em:italic prose-ul:text-lg prose-ol:text-lg prose-li:text-gray-800 prose-blockquote:border-l-4 prose-blockquote:border-blue-500  prose-blockquote:pl-4 prose-blockquote:italic prose-blockquote:text-gray-700 prose-blockquote:bg-blue-50 prose-blockquote:py-2 prose-blockquote:my-4 prose-code:bg-gray-100 prose-code:px-1 prose-code:py-0.5 prose-code:rounded  prose-code:text-sm prose-code:text-red-600 prose-pre:bg-gray-900 prose-pre:text-gray-100 prose-pre:p-4  prose-pre:rounded-lg prose-pre:overflow-x-auto prose-pre:my-4 14:T3d5a,<p>人工知能は機械学習という技術により、知的な振る舞いができるようになります。</p>
<p>その学習は人間が開発した手順に則って行われますが、なぜその手順と人工知能の構造から知性が生じるのかは、まだ説明できているわけではありません。</p>
<p>この記事では、学習というものの本質について考えることで、知性が生じる理由を探っていきたいと思います。</p>
<p>そして、学習についての考えを突き詰めていくと、人工知能も、私たちの脳も、生まれながらにして学習方法を学習していく性質を持っているという考えに行き着きます。</p>
<p>そこには、ナチュラルボーンフレームワーカーと呼ぶことができるメカニズムが存在していることが示唆されます。</p>
<h2>身体による学習と言葉による学習</h2>
<p>私たちは、物を目で見たり、体を動かしたりして、自分の身の回りの世界を知り、自分のできることを増やしていきます。</p>
<p>これも一種の学習です。身体による学習と呼ぶことができます。</p>
<p>一方で、一般に学習と言えば、教科書を読んだり教師の説明を聞いて、知識を増やしていくことをイメージするでしょう。</p>
<p>そうした教育カリキュラムに基づく学習の他にも、友人との会話やネットニュースなどからも様々な知識を得ます。</p>
<p>このような学習は、視覚的に画像を覚えたり、体を動かして覚えるような学習ではなく、言葉による学習です。</p>
<h2>形而下の学習と形而上の学習</h2>
<p>言葉による学習の中には、繰り返し反復しなければ覚えられない場合と、一度、あるいは数回聞けば覚えられるケースがあります。</p>
<p>あるいは、詳細は覚えてはいなくても、必要なタイミングで本棚やインターネットから詳細を取り出せば使えるという知識もあります。</p>
<p>知識を取得して必要な時に適切に利用するという意味で、これらいずれのパターンも学習と言えます。</p>
<p>これらのうち、繰り返し反復しなければ覚えられない知識は、形而下の知識と呼ぶことができます。その学習は、概念自体を覚える形而下の学習です。</p>
<p>これは目で物を見たり、体を動かしたりすることで反復学習する身体的な学習と同様です。これらも形而下の学習に分類できます。</p>
<p>一方で、少ない回数で覚えたり、その場で調べて使うことができる知識の習得は、形而上の学習と呼ぶことができます。</p>
<p>この場合、形而下の学習によって学習済みの概念を利用して、その概念の類型や、概念同士の組み合わせとして知識を学習することができます。</p>
<p>既に形而下の学習で習得済みの概念を利用することができるため、形而上の学習は反復が不要になるのです。</p>
<h2>自然言語機械学習</h2>
<p>これを人工知能における機械学習に当てはめて考えてみます。</p>
<p>一般に、機械学習に使われるニューラルネットワークは、反復を伴って概念を学習する形而下の学習を行っています。</p>
<p>一方で、人間と同様の自然言語処理が可能な大規模言語モデルは、言葉による学習が可能です。</p>
<p>大規模言語モデルの事前学習やファインチューニングにおいては、言葉による形而下の学習が行われます。</p>
<p>そして、学習済みの大規模言語モデルは、入力された文に含まれている知識を利用して回答することができるため、即時的な形而上の学習を行なっていることになります。</p>
<p>この言葉による形而上の学習の能力により、大規模言語モデルは反復的な学習をせずとも、新しい知識を活用することができます。</p>
<p>これは、従来のモデルのパラメータの調整を反復的に行う数値型の機械学習と対置する、自然言語機械学習と呼ぶことができます。</p>
<h2>形而界面としての自然言語</h2>
<p>形而下と形而上の学習を分けている界面には、自然言語が位置しています。</p>
<p>自然言語の興味深い点は、形而下の学習により習得ができる点と、その上に形而上の学習を可能にするという点です。</p>
<h2>自然言語以外の形而界面</h2>
<p>実際には、身体的な学習においても、形而下学習と形而上学習は存在します。例えば、スポーツが得意な人は、初めて知った競技にもすぐに適用できます。</p>
<p>また、生物に詳しい人は、新品種の生物を見た時に、すぐにその生物の特徴を理解することができます。</p>
<p>このように、身体的な学習においても、自然言語と同じような位置づけにある形而界面が存在することになります。</p>
<h2>フレームワーク</h2>
<p>これらの界面にあるのは、要素的な概念や知識とは別の、それらの関係や構造を規定したり、新たに構造化することを可能にするフレームワークです。</p>
<p>形而下の学習により多様な形而下の知識を学習していくと、形而下の知識同士のつながりから、形而界面にあるフレームワークを学習することができる場合があります。</p>
<p>身体的な学習によるフレームワークは、習得後に新しい知識を形而上の学習で即時的に行うことを可能にします。ただし、その形而上の学習により獲得した知識を、他の人に伝えることは容易ではありません。</p>
<p>一方で、言葉による学習によるフレームワークは、自然言語そのものです。</p>
<p>このため、自然言語というフレームワークを学習し、そこで形而上の学習により獲得した知識は、他の人の言葉による学習に直接インプットすることができます。</p>
<p>これは教科書やネットニュースのような言葉による学習が基本となるような知識だけではありません。</p>
<p>サッカーの経験者が初めて野球をして、その時に習得した野球における形而上の知識を、言葉にして他のサッカー経験者に伝えることができる可能性があります。同じ形而下の知識を持っている人であれば、いわゆる「コツ」と呼ばれるノウハウを言葉で伝えることができるということです。</p>
<p>また、他の生物学者に、自分が目撃した新種の生物について、言葉で伝えて知識を共有することもできるでしょう。</p>
<p>このように、自然言語は、形而界面にある非常に強力なフレームワークであることがわかります。</p>
<h2>仮想フレームワーク</h2>
<p>自然言語の上にも、別のフレームワークを習得することができます。</p>
<p>それは専門領域のフレームワークや、形而的なフレームワークです。</p>
<p>様々な学問領域やビジネス分野や、日常生活の中には、多種多様な専門領域のフレームワークがあります。</p>
<p>学者は専門分野のフレームワークの上で新しい発見をして、そのフレームワークを持つ別の学者に知識として容易にその発見を伝えることができるでしょう。</p>
<p>そのフレームワーク自体が自然言語の上で表現できることがあり、その場合には自然言語のフレームワークを持つ人や大規模言語モデルであれば習得して理解することができます。</p>
<p>ビジネスモデルや料理のレシピなども、こうした自然言語の上で表現可能な専門領域のフレームワークです。</p>
<p>また、数式やプログラミング言語、ビジネス分析のフレームワークなどは、形式的なフレームワークです。</p>
<p>これらも、そのフレームワーク自体を自然言語で表現したり説明することができます。</p>
<p>こうした自然言語の上の専門領域のフレームワークや形式的フレームワークは、仮想フレームワークと呼ぶことができます。</p>
<p>これは、物理的なコンピューターの上で別のOSを動作させる仮想マシンをイメージすると分かりやすいでしょう。自然言語という土台となるフレームワークの上で、別のフレームワークが機能しているわけです。</p>
<h2>ネイティブフレームワーク</h2>
<p>そして、この仮想フレームワークは、初めのうちは自然言語を介して理解しなければなりませんが、慣れてくると自然言語による説明や理解をバイパスして、直接的に形而下の知識の上にある形而界面のフレームワークとして機能するようになります。</p>
<p>それはネイティブフレームワークと呼ぶことができます。</p>
<p>自然言語も、ある意味ではネイティブフレームワークですが、それは母国語に限ります。一般に、母国語以外の言語は仮想フレームワークとして習得することになります。その習熟が進めば、ネイティブフレームワークに近づけていくことになります。</p>
<p>専門領域のフレームワークや形式的なフレームワークも同様です。数学者同士は数式でネイティブにコミュニケーションができ、プログラマーはコメント文のないソースコードだけで意図を理解し合うことができます。</p>
<p>これは、大規模言語モデルにも、仮想フレームワークからネイティブフレームワークへの流れを応用できることを示唆します。</p>
<p>繰り返し使用する仮想フレームワークを検出したら、その仮想フレームワークを用いた事例データを大量生成し、ファインチューニングしてネイティブフレームワーク化する、というアイデアは、今すぐにでも試してみる価値があるでしょう。</p>
<h2>ナチュラルボーンフレームワーカー</h2>
<p>このように考えてみると、大規模言語モデルのファインチューニングの際だけでなく、事前学習においても、こうした専門分野のフレームワークや形式的なフレームワークを学習している可能性があるということに気づきます。</p>
<p>そして、その過程では、初めから専門分野のフレームワークや形式的フレームワークをネイティブに学習しているのではなく、先に自然言語のフレームワークを学習しつつ、その途中や習熟後に、専門分野のフレームワークや形式的なフレームワークを学習してネイティブフレームワーク化している可能性が考えられます。</p>
<p>この段階的フレームワーク学習を深掘りして考えると、自然言語の学習そのものも、非常に細かい段階的なフレームワーク学習の並行パイプライン学習になっている可能性も考えられます。</p>
<p>つまり、事前学習で与えられる学習データとしての大量のテキストから、個々の概念だけでなく、自然言語のごくシンプルないくつかの規則をフレームワークとして学習していき、そのシンプルなフレームワークを土台として、もう少し複雑な規則を学習するということを繰り返しているのではないかということです。</p>
<p>こうして、初めは単語の概念を学習していた段階から、複合語や簡単な文法を覚え、そして文を理解したり、文章や表現のテクニックなど複雑な物を学習していく、ということができるはずです。</p>
<p>フレームワークを土台に次のフレームワークを覚えていくという段階的で複合的なフレームワークの学習をしているというモデルとして理解できます。</p>
<p>これは、フレームワークを学習する仕組みを初めから有している、ナチュラルボーンフレームワーカーとしての大規模言語モデルの姿を浮き彫りにします。</p>
<h2>アテンションメカニズム</h2>
<p>ナチュラルボーンフレームワーカーを実現している技術が、アテンションメカニズムです。</p>
<p>アテンションメカニズムは、文脈の中から注目すべきトークンを選択しているようなものです。そして、トークン間の関係を明確にしています。これはまさに重要な概念を残して抽象化しつつ、概念同士の関係を明確にするというフレームワークの性質そのものです。</p>
<p>その選択をトークンごとに切り替えることで、動的にフレームワークも切り替えていくことを可能にしています。</p>
<p>これによって、なぜアテンションメカニズムが大規模言語モデルの進化を決定づける技術であるのかを、ナチュラルボーンフレームワーカーというモデルで説明できます。</p>
<h2>さいごに</h2>
<p>このメカニズムが実際に大規模言語モデルの事前学習の過程で起きているとすれば、謎に包まれていた大規模言語モデルのメカニズムが説明可能になります。</p>
<p>それは、ここで議論してきた形而下と形而上の学習、形而界面としてのフレームワーク、言葉による学習と仮想フレームワークを可能にする自然言語、そしてナチュラルボーンフレームワーカーを実現するアテンションメカニズムです。</p>
<p>そして、そこからさらに2つのことが示唆されます。</p>
<p>1つは、自然言語が、シンプルなフレームワークから段階的に複雑なフレームワークをネイティブ化するのに非常に適した構造を持っている、ということです。</p>
<p>自然言語が人間の社会の中で初めはシンプルな形で出現し、そこから少しずつ複雑で豊かな構造を持つように成長してきたのだとすれば、これは当然の帰結です。</p>
<p>さらに、それがいち早く学習できるような構造になっている方が有利です。様々な自然言語を持つ複数の社会同士が競争していたと想定すれば、より学習に適した自然言語が現在生き残っているという仮説は容易に成り立ちます。</p>
<p>この自然言語の性質を振り返ると、2つ目の示唆につながります。それは、私たち人間も、ナチュラルボーンフレームワーカーである、ということです。</p>
<p>具体的な基盤やメカニズムは異なるとしても、私たちの脳にも、アテンションメカニズムのような、フレームワークを段階的に学習し、柔軟に変化させる仕組みが備わっているはずです。</p>6:["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":[["$","nav",null,{"className":"mb-8","children":["$","$L4",null,{"href":"/ja/articles","className":"text-blue-600 hover:text-blue-800 text-sm","children":["← ","記事一覧に戻る"]}]}],["$","nav",null,{"className":"mb-8","children":["$","div",null,{"className":"flex justify-between items-center","children":[["$","div",null,{"className":"flex-1","children":["$","$L4",null,{"href":"/ja/articles/2025_08_12_simulation-thinking-era","className":"group block max-w-sm","children":[["$","div",null,{"className":"text-sm text-gray-500 mb-1","children":"← 前の記事"}],["$","div",null,{"className":"text-lg font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2","children":"シミュレーション思考の時代"}],["$","div",null,{"className":"text-sm text-gray-400 mt-1","children":"2025年8月12日"}]]}]}],["$","div",null,{"className":"flex-1 text-right","children":["$","$L4",null,{"href":"/ja/articles/2025_08_14_concept-gestalt-collapse","className":"group block max-w-sm ml-auto","children":[["$","div",null,{"className":"text-sm text-gray-500 mb-1","children":"次の記事 →"}],["$","div",null,{"className":"text-lg font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2","children":"観念ゲシュタルト崩壊"}],["$","div",null,{"className":"text-sm text-gray-400 mt-1","children":"2025年8月14日"}]]}]}]]}]}],["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-4","children":"学習の学習：生まれながらの知性"}],["$","div",null,{"className":"flex items-center text-gray-600 text-sm mb-8","children":["$","$L4",null,{"href":"/ja/archive/2025/08","className":"text-blue-600 hover:text-blue-800 transition-colors","title":"この年月の記事一覧を見る","children":["$","time",null,{"dateTime":"2025-08-13","children":"2025年8月13日"}]}]}]]}],["$","div",null,{"className":"article-content","children":["$","article",null,{"className":"$13","dangerouslySetInnerHTML":{"__html":"$14"}}]}],"$L15","$L16","$L17"]}]
16:["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":[["$","h3",null,{"className":"text-xl font-bold text-gray-900 mb-6","children":"関連記事"}],["$","div",null,{"className":"grid gap-4 md:grid-cols-2","children":[["$","$L4","2025/08_06_Micro-VM-Intelligence",{"href":"/ja/articles/2025_08_06_micro-vm-intelligence","className":"group block p-4 bg-gray-50 hover:bg-gray-100 rounded-lg transition-colors","children":["$","div",null,{"className":"flex items-start justify-between","children":[["$","div",null,{"className":"flex-1","children":[["$","h4",null,{"className":"font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2 mb-2","children":"マイクロ仮想知能としてのアテンションメカニズム"}],["$","div",null,{"className":"flex items-center space-x-3 text-xs text-gray-500","children":[["$","span",null,{"className":"bg-white px-2 py-1 rounded","children":["関連度",": ",41,"%"]}],["$","span",null,{"className":"bg-white px-2 py-1 rounded capitalize","children":"similar"}]]}]]}],["$","svg",null,{"className":"w-4 h-4 text-gray-400 group-hover:text-blue-600 transition-colors flex-shrink-0 mt-1","fill":"currentColor","viewBox":"0 0 20 20","children":["$","path",null,{"fillRule":"evenodd","d":"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z","clipRule":"evenodd"}]}]]}]}],["$","$L4","2025/08_09_ALIS-Concept",{"href":"/ja/articles/2025_08_09_alis-concept","className":"group block p-4 bg-gray-50 hover:bg-gray-100 rounded-lg transition-colors","children":["$","div",null,{"className":"flex items-start justify-between","children":[["$","div",null,{"className":"flex-1","children":[["$","h4",null,{"className":"font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2 mb-2","children":"人工学習知能システム：ALIS構想"}],["$","div",null,{"className":"flex items-center space-x-3 text-xs text-gray-500","children":[["$","span",null,{"className":"bg-white px-2 py-1 rounded","children":["関連度",": ",35,"%"]}],["$","span",null,{"className":"bg-white px-2 py-1 rounded capitalize","children":"similar"}]]}]]}],["$","svg",null,{"className":"w-4 h-4 text-gray-400 group-hover:text-blue-600 transition-colors flex-shrink-0 mt-1","fill":"currentColor","viewBox":"0 0 20 20","children":["$","path",null,{"fillRule":"evenodd","d":"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z","clipRule":"evenodd"}]}]]}]}],["$","$L4","2025/06_29_Framework-Design-Ability",{"href":"/ja/articles/2025_06_29_framework-design-ability","className":"group block p-4 bg-gray-50 hover:bg-gray-100 rounded-lg transition-colors","children":["$","div",null,{"className":"flex items-start justify-between","children":[["$","div",null,{"className":"flex-1","children":[["$","h4",null,{"className":"font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2 mb-2","children":"フレームワーク設計という知的能力"}],["$","div",null,{"className":"flex items-center space-x-3 text-xs text-gray-500","children":[["$","span",null,{"className":"bg-white px-2 py-1 rounded","children":["関連度",": ",33,"%"]}],["$","span",null,{"className":"bg-white px-2 py-1 rounded capitalize","children":"similar"}]]}]]}],["$","svg",null,{"className":"w-4 h-4 text-gray-400 group-hover:text-blue-600 transition-colors flex-shrink-0 mt-1","fill":"currentColor","viewBox":"0 0 20 20","children":["$","path",null,{"fillRule":"evenodd","d":"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z","clipRule":"evenodd"}]}]]}]}],["$","$L4","2025/08_08_Natural-Language-ML",{"href":"/ja/articles/2025_08_08_natural-language-ml","className":"group block p-4 bg-gray-50 hover:bg-gray-100 rounded-lg transition-colors","children":["$","div",null,{"className":"flex items-start justify-between","children":[["$","div",null,{"className":"flex-1","children":[["$","h4",null,{"className":"font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2 mb-2","children":"自然言語機械学習"}],"$L18"]}],"$L19"]}]}],"$L1a"]}]]}]
17:["$","nav",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":["$","div",null,{"className":"flex justify-between items-center","children":[["$","div",null,{"className":"flex-1","children":["$","$L4",null,{"href":"/ja/articles/2025_08_12_simulation-thinking-era","className":"group block max-w-sm","children":[["$","div",null,{"className":"text-sm text-gray-500 mb-1","children":"← 前の記事"}],["$","div",null,{"className":"text-lg font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2","children":"シミュレーション思考の時代"}],["$","div",null,{"className":"text-sm text-gray-400 mt-1","children":"2025年8月12日"}]]}]}],["$","div",null,{"className":"flex-1 text-right","children":["$","$L4",null,{"href":"/ja/articles/2025_08_14_concept-gestalt-collapse","className":"group block max-w-sm ml-auto","children":[["$","div",null,{"className":"text-sm text-gray-500 mb-1","children":"次の記事 →"}],["$","div",null,{"className":"text-lg font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2","children":"観念ゲシュタルト崩壊"}],["$","div",null,{"className":"text-sm text-gray-400 mt-1","children":"2025年8月14日"}]]}]}]]}]}]
18:["$","div",null,{"className":"flex items-center space-x-3 text-xs text-gray-500","children":[["$","span",null,{"className":"bg-white px-2 py-1 rounded","children":["関連度",": ",33,"%"]}],["$","span",null,{"className":"bg-white px-2 py-1 rounded capitalize","children":"tag_based"}]]}]
19:["$","svg",null,{"className":"w-4 h-4 text-gray-400 group-hover:text-blue-600 transition-colors flex-shrink-0 mt-1","fill":"currentColor","viewBox":"0 0 20 20","children":["$","path",null,{"fillRule":"evenodd","d":"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z","clipRule":"evenodd"}]}]
1a:["$","$L4","2025/07_28_Liquidware-Allrounder",{"href":"/ja/articles/2025_07_28_liquidware-allrounder","className":"group block p-4 bg-gray-50 hover:bg-gray-100 rounded-lg transition-colors","children":["$","div",null,{"className":"flex items-start justify-between","children":[["$","div",null,{"className":"flex-1","children":[["$","h4",null,{"className":"font-medium text-gray-900 group-hover:text-blue-600 transition-colors line-clamp-2 mb-2","children":"リキッドウェア時代の全方位エンジニア"}],["$","div",null,{"className":"flex items-center space-x-3 text-xs text-gray-500","children":[["$","span",null,{"className":"bg-white px-2 py-1 rounded","children":["関連度",": ",33,"%"]}],["$","span",null,{"className":"bg-white px-2 py-1 rounded capitalize","children":"tag_based"}]]}]]}],["$","svg",null,{"className":"w-4 h-4 text-gray-400 group-hover:text-blue-600 transition-colors flex-shrink-0 mt-1","fill":"currentColor","viewBox":"0 0 20 20","children":["$","path",null,{"fillRule":"evenodd","d":"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z","clipRule":"evenodd"}]}]]}]}]
15:["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200 space-y-6","children":[["$","div",null,{"children":[["$","h3",null,{"className":"text-lg font-semibold text-gray-900 mb-3","children":"カテゴリ"}],["$","div",null,{"className":"space-y-2","children":[["$","div","0",{"className":"flex items-center space-x-2","children":["$","div",null,{"className":"flex items-center space-x-1 text-sm","children":[["$","div","0",{"className":"flex items-center space-x-1","children":[false,"$L1b"]}],["$","div","1",{"className":"flex items-center space-x-1","children":[["$","span",null,{"className":"text-gray-400","children":"→"}],"$L1c"]}]]}]}],["$","div","1",{"className":"flex items-center space-x-2","children":["$","div",null,{"className":"flex items-center space-x-1 text-sm","children":[["$","div","0",{"className":"flex items-center space-x-1","children":[false,"$L1d"]}],["$","div","1",{"className":"flex items-center space-x-1","children":[["$","span",null,{"className":"text-gray-400","children":"→"}],"$L1e"]}]]}]}]]}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-lg font-semibold text-gray-900 mb-3","children":"タグ"}],["$","div",null,{"className":"flex flex-wrap gap-2","children":["$L1f","$L20","$L21","$L22","$L23","$L24","$L25","$L26","$L27","$L28","$L29","$L2a","$L2b","$L2c","$L2d","$L2e","$L2f","$L30","$L31","$L32"]}]]}]]}]
1b:["$","$L4",null,{"href":"/ja/categories/technology","className":"text-blue-600 hover:text-blue-800 bg-blue-50 hover:bg-blue-100 px-2 py-1 rounded transition-colors","children":"テクノロジー"}]
1c:["$","$L4",null,{"href":"/ja/categories/artificial-intelligence","className":"text-blue-600 hover:text-blue-800 bg-blue-50 hover:bg-blue-100 px-2 py-1 rounded transition-colors","children":"人工知能"}]
1d:["$","$L4",null,{"href":"/ja/categories/science-academics","className":"text-blue-600 hover:text-blue-800 bg-blue-50 hover:bg-blue-100 px-2 py-1 rounded transition-colors","children":"科学・学術"}]
1e:["$","$L4",null,{"href":"/ja/categories/nature-of-knowledge","className":"text-blue-600 hover:text-blue-800 bg-blue-50 hover:bg-blue-100 px-2 py-1 rounded transition-colors","children":"知のあり方"}]
1f:["$","$L4","0",{"href":"/ja/tags/natural-born-frameworker","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","ナチュラルボーンフレームワーカー"]}]
20:["$","$L4","1",{"href":"/ja/tags/sublunary-learning","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","形而下の学習"]}]
21:["$","$L4","2",{"href":"/ja/tags/metaphysical-learning","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","形而上の学習"]}]
22:["$","$L4","3",{"href":"/ja/tags/metaphysical-interface","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","形而界面"]}]
23:["$","$L4","4",{"href":"/ja/tags/framework","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","フレームワーク"]}]
24:["$","$L4","5",{"href":"/ja/tags/virtual-framework","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","仮想フレームワーク"]}]
25:["$","$L4","6",{"href":"/ja/tags/native-framework","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","ネイティブフレームワーク"]}]
26:["$","$L4","7",{"href":"/ja/tags/natural-language-machine-learning","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","自然言語機械学習"]}]
27:["$","$L4","8",{"href":"/ja/tags/learning-by-doing","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","身体による学習"]}]
28:["$","$L4","9",{"href":"/ja/tags/learning-by-language","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","言葉による学習"]}]
29:["$","$L4","10",{"href":"/ja/tags/large-language-model","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","大規模言語モデル"]}]
2a:["$","$L4","11",{"href":"/ja/tags/machine-learning","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","機械学習"]}]
2b:["$","$L4","12",{"href":"/ja/tags/neural-network","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","ニューラルネットワーク"]}]
2c:["$","$L4","13",{"href":"/ja/tags/natural-language-processing","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","自然言語処理"]}]
2d:["$","$L4","14",{"href":"/ja/tags/pretraining","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","事前学習"]}]
2e:["$","$L4","15",{"href":"/ja/tags/fine-tuning","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","ファインチューニング"]}]
2f:["$","$L4","16",{"href":"/ja/tags/attention-mechanism","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","アテンションメカニズム"]}]
30:["$","$L4","17",{"href":"/ja/tags/singularity","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","シンギュラリティ"]}]
31:["$","$L4","18",{"href":"/ja/tags/cognitive-science","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","認知科学"]}]
32:["$","$L4","19",{"href":"/ja/tags/artificial-intelligence","className":"inline-block px-3 py-1 bg-gray-100 hover:bg-gray-200 text-gray-700 hover:text-gray-900 text-sm rounded-full transition-colors","children":["#","人工知能"]}]
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
a:{"metadata":[["$","title","0",{"children":"学習の学習：生まれながらの知性 | katoshiの研究ノート"}],["$","meta","1",{"name":"description","content":"本記事は、知性がどのように生じるのかという問いに対し、人工知能（AI）の学習メカニズムと人間の学習プロセスを対比させながら、学習の本質と「フレームワーク」という概念を通じて考察する。AIにおける機械学習は、ニューラルネットワークによる反復的な「形而下の学習」が中心だが、大規模言語モデル（LLM）は自然言語を介した「形而上の学習」を可能にする。これは、概念を一度習得すれば、反復なしに新しい知識を活用する能力であり、「自然言語機械学習」と定義される。自然言語は、形而下の学習で習得可能でありながら、形而上の学習を促進する「形而界面」として機能する。身体的学習においても、スポーツや生物学の知識習得に見られるように、自然言語と同様の形而界面が存在する。これらの界面には、要素間の関係性や構造を規定する「フレームワーク」が存在する。形而下の学習で蓄積された知識から、形而界面のフレームワークを学習でき、身体的学習のフレームワークは即時的な形而上学習を可能にするが、他者への伝達が困難である。一方、自然言語というフレームワークを介した形而上学習の知識は、他者と共有しやすい。自然言語の上に構築される専門領域や形式的な「仮想フレームワーク」は、習熟により「ネイティブフレームワーク」へと移行する。LLMの学習プロセスも、自然言語フレームワークを土台に、仮想フレームワークをネイティブ化する段階的学習と捉えられる。このナチュラルボーンフレームワーカーとも呼べるAIの学習メカニズムは、「アテンションメカニズム」によって実現されている。アテンションメカニズムは、文脈から注目すべきトークンを選択し、トークン間の関係を明確にすることで、フレームワークの学習と動的な切り替えを可能にする。このメカニズムは、LLMの進化の鍵であると同時に、人間もまた、フレームワークを段階的に学習し柔軟に変化させる仕組みを備えた「ナチュラルボーンフレームワーカー」であるという示唆につながる。自然言語の構造自体も、学習に適した進化を遂げてきた可能性が示唆されている。"}],["$","meta","2",{"name":"author","content":"katoshi"}],["$","meta","3",{"name":"keywords","content":"AI,ソフトウェア開発,システム設計,生命科学,博士,エンジニア,研究,思考法,シミュレーション思考,リキッドウェア,フレームワーク設計,仮想知能"}],["$","meta","4",{"name":"creator","content":"katoshi"}],["$","meta","5",{"name":"publisher","content":"katoshiの研究ノート"}],["$","meta","6",{"name":"robots","content":"index, follow"}],["$","meta","7",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","8",{"rel":"canonical","href":"https://katoshi-mfacet.github.io/ja/articles/2025_08_13_natural-born-frameworker/"}],["$","meta","9",{"property":"og:title","content":"学習の学習：生まれながらの知性 | katoshiの研究ノート"}],["$","meta","10",{"property":"og:description","content":"本記事は、知性がどのように生じるのかという問いに対し、人工知能（AI）の学習メカニズムと人間の学習プロセスを対比させながら、学習の本質と「フレームワーク」という概念を通じて考察する。AIにおける機械学習は、ニューラルネットワークによる反復的な「形而下の学習」が中心だが、大規模言語モデル（LLM）は自然言語を介した「形而上の学習」を可能にする。これは、概念を一度習得すれば、反復なしに新しい知識を活用する能力であり、「自然言語機械学習」と定義される。自然言語は、形而下の学習で習得可能でありながら、形而上の学習を促進する「形而界面」として機能する。身体的学習においても、スポーツや生物学の知識習得に見られるように、自然言語と同様の形而界面が存在する。これらの界面には、要素間の関係性や構造を規定する「フレームワーク」が存在する。形而下の学習で蓄積された知識から、形而界面のフレームワークを学習でき、身体的学習のフレームワークは即時的な形而上学習を可能にするが、他者への伝達が困難である。一方、自然言語というフレームワークを介した形而上学習の知識は、他者と共有しやすい。自然言語の上に構築される専門領域や形式的な「仮想フレームワーク」は、習熟により「ネイティブフレームワーク」へと移行する。LLMの学習プロセスも、自然言語フレームワークを土台に、仮想フレームワークをネイティブ化する段階的学習と捉えられる。このナチュラルボーンフレームワーカーとも呼べるAIの学習メカニズムは、「アテンションメカニズム」によって実現されている。アテンションメカニズムは、文脈から注目すべきトークンを選択し、トークン間の関係を明確にすることで、フレームワークの学習と動的な切り替えを可能にする。このメカニズムは、LLMの進化の鍵であると同時に、人間もまた、フレームワークを段階的に学習し柔軟に変化させる仕組みを備えた「ナチュラルボーンフレームワーカー」であるという示唆につながる。自然言語の構造自体も、学習に適した進化を遂げてきた可能性が示唆されている。"}],["$","meta","11",{"property":"og:url","content":"https://katoshi-mfacet.github.io/ja/articles/2025_08_13_natural-born-frameworker/"}],["$","meta","12",{"property":"og:site_name","content":"katoshiの研究ノート"}],["$","meta","13",{"property":"og:locale","content":"ja_JP"}],["$","meta","14",{"property":"og:type","content":"article"}],["$","meta","15",{"property":"article:published_time","content":"2025-08-13"}],["$","meta","16",{"property":"article:tag","content":"ナチュラルボーンフレームワーカー"}],["$","meta","17",{"property":"article:tag","content":"形而下の学習"}],["$","meta","18",{"property":"article:tag","content":"形而上の学習"}],["$","meta","19",{"property":"article:tag","content":"形而界面"}],["$","meta","20",{"property":"article:tag","content":"フレームワーク"}],["$","meta","21",{"property":"article:tag","content":"仮想フレームワーク"}],["$","meta","22",{"property":"article:tag","content":"ネイティブフレームワーク"}],["$","meta","23",{"property":"article:tag","content":"自然言語機械学習"}],["$","meta","24",{"property":"article:tag","content":"身体による学習"}],["$","meta","25",{"property":"article:tag","content":"言葉による学習"}],["$","meta","26",{"property":"article:tag","content":"大規模言語モデル"}],"$L33","$L34","$L35","$L36","$L37","$L38","$L39","$L3a","$L3b","$L3c","$L3d","$L3e","$L3f","$L40","$L41"],"error":null,"digest":"$undefined"}
42:I[8175,[],"IconMark"]
33:["$","meta","27",{"property":"article:tag","content":"機械学習"}]
34:["$","meta","28",{"property":"article:tag","content":"ニューラルネットワーク"}]
35:["$","meta","29",{"property":"article:tag","content":"自然言語処理"}]
36:["$","meta","30",{"property":"article:tag","content":"事前学習"}]
37:["$","meta","31",{"property":"article:tag","content":"ファインチューニング"}]
38:["$","meta","32",{"property":"article:tag","content":"アテンションメカニズム"}]
39:["$","meta","33",{"property":"article:tag","content":"シンギュラリティ"}]
3a:["$","meta","34",{"property":"article:tag","content":"認知科学"}]
3b:["$","meta","35",{"property":"article:tag","content":"人工知能"}]
3c:["$","meta","36",{"name":"twitter:card","content":"summary_large_image"}]
3d:["$","meta","37",{"name":"twitter:creator","content":"@katoshi_mfacet"}]
3e:["$","meta","38",{"name":"twitter:title","content":"学習の学習：生まれながらの知性 | katoshiの研究ノート"}]
3f:["$","meta","39",{"name":"twitter:description","content":"本記事は、知性がどのように生じるのかという問いに対し、人工知能（AI）の学習メカニズムと人間の学習プロセスを対比させながら、学習の本質と「フレームワーク」という概念を通じて考察する。AIにおける機械学習は、ニューラルネットワークによる反復的な「形而下の学習」が中心だが、大規模言語モデル（LLM）は自然言語を介した「形而上の学習」を可能にする。これは、概念を一度習得すれば、反復なしに新しい知識を活用する能力であり、「自然言語機械学習」と定義される。自然言語は、形而下の学習で習得可能でありながら、形而上の学習を促進する「形而界面」として機能する。身体的学習においても、スポーツや生物学の知識習得に見られるように、自然言語と同様の形而界面が存在する。これらの界面には、要素間の関係性や構造を規定する「フレームワーク」が存在する。形而下の学習で蓄積された知識から、形而界面のフレームワークを学習でき、身体的学習のフレームワークは即時的な形而上学習を可能にするが、他者への伝達が困難である。一方、自然言語というフレームワークを介した形而上学習の知識は、他者と共有しやすい。自然言語の上に構築される専門領域や形式的な「仮想フレームワーク」は、習熟により「ネイティブフレームワーク」へと移行する。LLMの学習プロセスも、自然言語フレームワークを土台に、仮想フレームワークをネイティブ化する段階的学習と捉えられる。このナチュラルボーンフレームワーカーとも呼べるAIの学習メカニズムは、「アテンションメカニズム」によって実現されている。アテンションメカニズムは、文脈から注目すべきトークンを選択し、トークン間の関係を明確にすることで、フレームワークの学習と動的な切り替えを可能にする。このメカニズムは、LLMの進化の鍵であると同時に、人間もまた、フレームワークを段階的に学習し柔軟に変化させる仕組みを備えた「ナチュラルボーンフレームワーカー」であるという示唆につながる。自然言語の構造自体も、学習に適した進化を遂げてきた可能性が示唆されている。"}]
40:["$","link","40",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x32"}]
41:["$","$L42","41",{}]
f:"$a:metadata"
