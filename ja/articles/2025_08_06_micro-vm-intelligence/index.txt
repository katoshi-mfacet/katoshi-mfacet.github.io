1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
6:I[9665,[],"OutletBoundary"]
8:I[4911,[],"AsyncMetadataOutlet"]
a:I[9665,[],"ViewportBoundary"]
c:I[9665,[],"MetadataBoundary"]
d:"$Sreact.suspense"
f:I[8393,[],""]
:HL["/_next/static/media/569ce4b8f30dc480-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/c2bb066bad6269d3.css","style"]
0:{"P":null,"b":"IaZ2UV3FR3Bf3GP2RYkxg","p":"","c":["","ja","articles","2025_08_06_micro-vm-intelligence",""],"i":false,"f":[[["",{"children":[["lang","ja","d"],{"children":["articles",{"children":[["slug","2025_08_06_micro-vm-intelligence","d"],{"children":["__PAGE__",{}]}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/c2bb066bad6269d3.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__variable_5cfdac __variable_9a8899 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":[["lang","ja","d"],["$","$1","c",{"children":[null,"$L4"]}],{"children":["articles",["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","2025_08_06_micro-vm-intelligence","d"],["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$L7",["$","$L8",null,{"promise":"$@9"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$La",null,{"children":"$Lb"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Lc",null,{"children":["$","div",null,{"hidden":true,"children":["$","$d",null,{"fallback":null,"children":"$Le"}]}]}]]}],false]],"m":"$undefined","G":["$f",[]],"s":false,"S":true}
10:I[6744,["874","static/chunks/874-437a265a67d6cfee.js","160","static/chunks/app/%5Blang%5D/layout-0c325a600f86f170.js"],"default"]
4:["$","div",null,{"children":[["$","header",null,{"className":"bg-white shadow-sm","children":["$","div",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"flex justify-between items-center py-4","children":[["$","h1",null,{"className":"text-xl font-bold","children":"Blog Site"}],["$","$L10",null,{"currentLang":"ja"}]]}]}]}],["$","main",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]
11:I[6874,["874","static/chunks/874-437a265a67d6cfee.js","937","static/chunks/app/%5Blang%5D/articles/%5Bslug%5D/page-19852b7779f6e4e0.js"],""]
12:T456,prose prose-lg max-w-none prose-headings:text-gray-900 prose-headings:font-bold prose-h1:text-3xl prose-h1:mb-6 prose-h1:mt-8 prose-h1:border-b prose-h1:border-gray-200 prose-h1:pb-2 prose-h2:text-2xl prose-h2:mb-4 prose-h2:mt-8 prose-h2:border-b prose-h2:border-gray-100 prose-h2:pb-2 prose-h3:text-xl prose-h3:mb-3 prose-h3:mt-6 prose-h4:text-lg prose-h4:mb-2 prose-h4:mt-4 prose-p:text-lg prose-p:leading-relaxed prose-p:text-gray-800 prose-a:text-blue-600 prose-a:hover:text-blue-800 prose-a:underline prose-strong:text-gray-900 prose-strong:font-semibold prose-em:text-gray-700 prose-em:italic prose-ul:text-lg prose-ol:text-lg prose-li:text-gray-800 prose-blockquote:border-l-4 prose-blockquote:border-blue-500  prose-blockquote:pl-4 prose-blockquote:italic prose-blockquote:text-gray-700 prose-blockquote:bg-blue-50 prose-blockquote:py-2 prose-blockquote:my-4 prose-code:bg-gray-100 prose-code:px-1 prose-code:py-0.5 prose-code:rounded  prose-code:text-sm prose-code:text-red-600 prose-pre:bg-gray-900 prose-pre:text-gray-100 prose-pre:p-4  prose-pre:rounded-lg prose-pre:overflow-x-auto prose-pre:my-4 13:T1fa0,<p>現在の生成AIは、トランスフォーマーが発明されたことが大きなブレークスルーとなって開花したAI技術です。</p>
<p>トランスフォーマーの特徴を一言で表すのが、アテンションメカニズムです。これはトランスフォーマーが発表された際の論文のタイトル“Attention is All You Need” にも端的に表れています。</p>
<p>これは、当時のAIの研究者たちが、AIが自然言語を人間のように上手く扱えるように様々な工夫や試行錯誤をして、様々な上手くいった方法に名前を付けて論文を発表していたという背景があります。</p>
<p>そして、多くの研究者たちは、それらの複数の上手く機能する仕組みを、多種多様に組み合わせていくことで、徐々に人間のように自然言語を扱えるAIができると考えており、他の仕組みと組み合わせて機能する新しい仕組みを見つけたり、それらの仕組みの最適な組み合わせを見つけることに取り組んでいたのです。</p>
<p>しかし、このトランスフォーマーは、その常識を覆しました。様々な仕組みを組み合わせる必要はない、必要なのはアテンションメカニズムだけだ、というメッセージが、論文のタイトルに表れています。</p>
<p>もちろんトランスフォーマー自体には様々なメカニズムが組み込まれていますが、その中でもアテンションメカニズムが特に画期的で、特徴的だったことは間違いないでしょう。</p>
<h2>アテンションメカニズムの概要</h2>
<p>アテンションメカニズムは、自然言語を単語単位で処理する過程で、ある単語を処理している際に、それまでの文に含まれる多数の単語のうち、どの単語に注意を向けるべきか、ということを学習できる仕組みです。</p>
<p>これにより、例えば「この」「その」「さっきの」のように以前の文の中に含まれている単語を指し示す言葉や、「冒頭の文」「2番目に挙げた例」「一つ前の段落」のように文章の位置を示すような言葉を含む場合に、それが何を指しているかを高い精度で理解することができます。</p>
<p>また、文中で修飾語が離れていても適切に解釈したり、文章が長文になっても、他の文に紛れて今の単語が触れている文脈を見失うことなく解釈できます。</p>
<p>これが「注意（アテンション）」の効用です。</p>
<p>これは、逆に言えば、今処理している単語を解釈する際に、不要な単語をマスクして解釈から除去している、とも言えます。</p>
<p>その単語の解釈に必要な単語だけを残して、無関係な単語を解釈から除去することで、どんなに長文になっても、解釈する単語の集合が少数に限定され、解釈の密度が薄くなることを避けることができます。</p>
<h2>仮想知能</h2>
<p>さて、話は少し変わりますが、私は仮想知能という概念について考えています。</p>
<p>現在、生成AIを業務利用する際に、企業内のあらゆる情報を一つまとめにして生成AIのナレッジとして与えてしまうと、ナレッジの量が多すぎて、却って適切にナレッジが扱えないという現象が起こります。</p>
<p>このため、業務によってナレッジを分けて、業務毎にAIチャットを用意したり、特定の作業に特化したAIツールを作る方がうまくいきます。</p>
<p>そうなると複合的な作業を行う場合、こうした分割されたナレッジを持つAIチャットやAIツールを組み合わせる必要があるということになります。</p>
<p>これは現在の生成AIを使用する場合の限界ですが、基本的には将来の生成AIであっても、特定の作業の際には、その作業に必要なナレッジだけに集中する方が精度が高くなるはずです。</p>
<p>その代わり、将来の生成AIは、人間がナレッジを分割しなくても、生成AIが状況に応じて必要なナレッジを内部で使い分けることができるようになるだろうと考えています。</p>
<p>この能力が仮想知能です。それは、仮想マシンが1つのコンピュータ上で複数の異なるOSを動作させることができる仮想マシンのようなものです。1つの知能の中で、異なる専門性を持つ仮想的な複数の知能を機能させることができるということです。</p>
<p>既に現在の生成AIであっても、複数の人による議論をシミュレートできていたり、複数の人物が登場する物語を生成できます。このため、仮想知能は特別な能力ではなく、現在の生成AIの延長線上にあります。</p>
<h2>マイクロ仮想知能</h2>
<p>作業に応じて必要なナレッジを絞る仮想知能の仕組みは、アテンションメカニズムに似たことをしています。</p>
<p>つまり、今、処理をしようとしている作業に応じて、関連するナレッジだけに絞って扱う、という点で、アテンションメカニズムに類似しています。</p>
<p>逆に言えば、アテンションメカニズムは、仮想知能のようなことを実現するメカニズムと言えます。ただし、私が考えている仮想知能は、ナレッジの集合の中から関連するナレッジを選び出す仕組みですが、アテンションメカニズムは単語の集合を単位としています。</p>
<p>このため、アテンションメカニズムは、マイクロ仮想知能と呼ぶことができます。</p>
<h2>明示的アテンションメカニズム</h2>
<p>アテンションメカニズムをマイクロ仮想知能として捉えると、反対に先ほど私が考えていると言った仮想知能は、マクロなアテンションメカニズムを構築することで実現できることが分かります。</p>
<p>そして、そのマクロなアテンションメカニズムは、大規模言語モデルの内部構造に付け加えたり、ニューラルネットワークによる学習を伴う必要はありません。</p>
<p>それは「作業Aを実行する際には、ナレッジBとナレッジCを参照すること」という自然言語で書かれた明示的な文で良いのです。</p>
<p>これにより作業Aに必要なナレッジが明確化されます。この文自体も、一種のナレッジです。</p>
<p>これは明示的アテンションメカニズムと呼ぶことができるでしょう。この文は、作業Aを実施する際に注意を向けるべきナレッジを明文化したアテンションナレッジと言えます。</p>
<p>そして、このアテンションナレッジは、生成AIに生成されたり更新させたりすることができます。</p>
<p>ある作業でナレッジ不足で失敗した場合、その反省としてその作業で参照すべきナレッジとして別のナレッジを追加するようにアテンションナレッジを更新させれば良いでしょう。</p>
<h2>さいごに</h2>
<p>アテンションメカニズムは、生成AIの能力を飛躍的に向上させました。</p>
<p>それは、たまたま上手く機能する機構だったわけではなく、ここで見てきたように、場面毎に参照する情報を動的に絞るというメカニズムそのものが、高度な知性の本質なのではないかと思えます。</p>
<p>そして、仮想知能や明示的なアテンションナレッジのように、アテンションメカニズムは再帰的に様々なレイヤで知能を高度化させるカギでもあります。</p>5:["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":[["$","nav",null,{"className":"mb-8","children":["$","$L11",null,{"href":"/ja/articles","className":"text-blue-600 hover:text-blue-800 text-sm","children":["← ","記事一覧に戻る"]}]}],["$","header",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-4xl font-bold text-gray-900 mb-4","children":"マイクロ仮想知能としてのアテンションメカニズム"}],["$","div",null,{"className":"flex items-center text-gray-600 text-sm mb-8","children":["$","time",null,{"dateTime":"2025-08-06","children":"2025年8月6日"}]}]]}],["$","div",null,{"className":"article-content","children":["$","article",null,{"className":"$12","dangerouslySetInnerHTML":{"__html":"$13"}}]}],"$L14"]}]
14:["$","div",null,{"className":"mt-12 pt-8 border-t border-gray-200","children":["$","p",null,{"className":"text-gray-500 text-sm","children":"カテゴリ、タグ、関連記事の表示は近日実装予定です"}]}]
b:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
15:I[8175,[],"IconMark"]
9:{"metadata":[["$","title","0",{"children":"Create Next App"}],["$","meta","1",{"name":"description","content":"Generated by create next app"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","$L15","3",{}]],"error":null,"digest":"$undefined"}
e:"$9:metadata"
