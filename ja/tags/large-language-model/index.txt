1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
4:I[6874,["408","static/chunks/app/%5Blang%5D/tags/%5Btag%5D/page-70e369dc1af8e3b1.js"],""]
7:I[9665,[],"OutletBoundary"]
9:I[4911,[],"AsyncMetadataOutlet"]
b:I[9665,[],"ViewportBoundary"]
d:I[9665,[],"MetadataBoundary"]
e:"$Sreact.suspense"
10:I[8393,[],""]
:HL["/_next/static/media/569ce4b8f30dc480-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/8478701d0f9a9ae4.css","style"]
0:{"P":null,"b":"4Nd80_Vfhl2EysN9DQEvW","p":"","c":["","ja","tags","large-language-model",""],"i":false,"f":[[["",{"children":[["lang","ja","d"],{"children":["tags",{"children":[["tag","large-language-model","d"],{"children":["__PAGE__",{}]}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/8478701d0f9a9ae4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"ja","children":["$","body",null,{"className":"__variable_5cfdac __variable_9a8899 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"min-h-screen bg-gray-50 flex flex-col justify-center py-12 sm:px-6 lg:px-8","children":["$","div",null,{"className":"sm:mx-auto sm:w-full sm:max-w-md","children":["$","div",null,{"className":"text-center","children":[["$","h1",null,{"className":"text-9xl font-bold text-gray-300","children":"404"}],["$","h2",null,{"className":"mt-4 text-3xl font-bold text-gray-900","children":"ページが見つかりません"}],["$","p",null,{"className":"mt-4 text-lg text-gray-600","children":"お探しのページは存在しないか、移動された可能性があります。"}],["$","div",null,{"className":"mt-8","children":["$","$L4",null,{"href":"/ja","className":"inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-md text-white bg-blue-600 hover:bg-blue-700 transition-colors","children":"ホームに戻る"}]}]]}]}]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":[["lang","ja","d"],["$","$1","c",{"children":[null,"$L5"]}],{"children":["tags",["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["tag","large-language-model","d"],["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":["$L8",["$","$L9",null,{"promise":"$@a"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},[["$","div","l",{"className":"min-h-screen bg-gray-50 flex items-center justify-center","children":["$","div",null,{"className":"animate-spin rounded-full h-12 w-12 border-b-2 border-blue-600"}]}],[],[]],false],["$","$1","h",{"children":[null,[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$Ld",null,{"children":["$","div",null,{"hidden":true,"children":["$","$e",null,{"fallback":null,"children":"$Lf"}]}]}]]}],false]],"m":"$undefined","G":["$10",[]],"s":false,"S":true}
5:["$","div",null,{"children":[["$","header",null,{"className":"bg-white shadow-sm","children":["$","div",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"flex justify-between items-center py-4","children":[["$","div",null,{"className":"flex items-center space-x-8","children":[["$","$L4",null,{"href":"/ja","className":"text-xl font-bold text-gray-900 hover:text-blue-600","children":"katoshiの研究ノート"}],["$","nav",null,{"className":"hidden md:flex space-x-6","children":[["$","$L4",null,{"href":"/ja/articles","className":"text-gray-600 hover:text-gray-900 font-medium","children":"記事一覧"}],["$","$L4",null,{"href":"/ja/categories","className":"text-gray-600 hover:text-gray-900 font-medium","children":"カテゴリ"}],["$","$L4",null,{"href":"/ja/archive","className":"text-gray-600 hover:text-gray-900 font-medium","children":"アーカイブ"}],["$","$L4",null,{"href":"/ja/vocabulary","className":"text-gray-600 hover:text-gray-900 font-medium","children":"用語集"}],["$","$L4",null,{"href":"/ja/about","className":"text-gray-600 hover:text-gray-900 font-medium","children":"About"}]]}]]}],["$","div",null,{"className":"flex items-center space-x-4","children":[["$","div",null,{"className":"flex items-center space-x-3","role":"list","children":[["$","a","X (Twitter)",{"href":"https://twitter.com/katoshi_mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"X (Twitter)","aria-label":"Xアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"}]}]}],["$","a","Note",{"href":"https://note.com/katoshi_mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"Note","aria-label":"Noteアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-1 16H6V5h12v14zM8 7h8v2H8V7zm0 4h8v2H8v-2zm0 4h5v2H8v-2z"}]}]}],["$","a","YouTube",{"href":"https://www.youtube.com/channel/UCRZjsc8pWWT8GQLBA6gc2MQ","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"YouTube","aria-label":"YouTubeチャンネルを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"}]}]}],["$","a","Medium",{"href":"https://medium.com/@katoshi-mfacet","target":"_blank","rel":"noopener noreferrer","className":"text-gray-600 hover:text-blue-600 transition-colors duration-200 p-1 rounded-sm focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2","title":"Medium","aria-label":"Mediumアカウントを見る","role":"listitem","children":["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"d":"M13.54 12a6.8 6.8 0 01-6.77 6.82A6.8 6.8 0 010 12a6.8 6.8 0 016.77-6.82A6.8 6.8 0 0113.54 12zM20.96 12c0 3.54-1.51 6.42-3.38 6.42-1.87 0-3.39-2.88-3.39-6.42s1.52-6.42 3.39-6.42 3.38 2.88 3.38 6.42M24 12c0 3.17-.53 5.75-1.19 5.75-.66 0-1.19-2.58-1.19-5.75s.53-5.75 1.19-5.75C23.47 6.25 24 8.83 24 12z"}]}]}]]}],"$L11"]}]]}]}]}],"$L12"]}]
11:["$","div",null,{"className":"flex gap-2 items-center","children":[["$","span",null,{"className":"text-sm text-gray-600","children":"Language:"}],[["$","a","ja",{"href":"/ja/","className":"px-2 py-1 text-sm rounded bg-blue-500 text-white","children":"日本語"}]]]}]
12:["$","main",null,{"children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]}]
6:["$","div",null,{"className":"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":[["$","nav",null,{"className":"mb-8","children":["$","div",null,{"className":"flex items-center space-x-2 text-sm","children":[["$","$L4",null,{"href":"/ja","className":"text-blue-600 hover:text-blue-800","children":"ホーム"}],["$","span",null,{"className":"text-gray-500","children":"→"}],["$","$L4",null,{"href":"/ja/articles","className":"text-blue-600 hover:text-blue-800","children":"記事一覧"}],["$","span",null,{"className":"text-gray-500","children":"→"}],["$","span",null,{"className":"text-gray-900","children":["#","大規模言語モデル"]}]]}]}],["$","header",null,{"className":"mb-12","children":[["$","div",null,{"className":"flex items-center mb-4","children":[["$","div",null,{"className":"bg-gray-100 p-3 rounded-full mr-4","children":["$","svg",null,{"className":"w-6 h-6 text-gray-600","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z"}]}]}],["$","div",null,{"children":[["$","h1",null,{"className":"text-4xl font-bold text-gray-900","children":["#","大規模言語モデル"]}],["$","p",null,{"className":"text-lg text-gray-600 mt-2","children":"「大規模言語モデル」タグが付いた記事一覧"}]]}]]}],["$","div",null,{"className":"text-sm text-gray-500","children":[6," ","件の記事"]}]]}],["$","div",null,{"className":"grid gap-6 md:grid-cols-2 lg:grid-cols-3","children":[["$","$L4","2025/08_13_Natural-Born-Frameworker",{"href":"/ja/articles/2025_08_13_natural-born-frameworker","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"学習の学習：生まれながらの知性"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年8月13日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本記事は、知性がどのように生じるのかという問いに対し、人工知能（AI）の学習メカニズムと人間の学習プロセスを対比させながら、学習の本質と「フレームワーク」という概念を通じて考察する。AIにおける機械学習は、ニューラルネットワークによる反復的な「形而下の学習」が中心だが、大規模言語モデル（LLM）は自然言語を介した「形而上の学習」を可能にする。これは、概念を一度習得すれば、反復なしに新しい知識を活用","..."]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"ナチュラルボーンフレームワーカー"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"形而下の学習"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"形而上の学習"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",17]}]]}]]}],["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]]}]}],["$","$L4","2025/08_12_Chronoscramble-Society",{"href":"/ja/articles/2025_08_12_chronoscramble-society","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"クロノスクランブル社会"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年8月12日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本記事は、生成AIの登場によって生じた、人々の時間認識の差異を「クロノスクランブル社会」と定義し、その性質と課題、そして対応策について論じている。従来、時間認識の差は国境、文化、世代に起因し、比較的可視的で解消も容易であった。しかし、生成AI、特に大規模言語モデルの登場により、AI技術の現在地や将来の見込みに関する認識差が、技術に詳しいか否かといった境界線なく、かつ解消困難な形で拡大している。この","..."]}],"$L13"]}],"$L14"]}]}],"$L15","$L16","$L17","$L18"]}]]}]
13:["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"クロノスクランブル社会"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"生成AI"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"大規模言語モデル"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",17]}]]}]
14:["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]
15:["$","$L4","2025/08_09_ALIS-Concept",{"href":"/ja/articles/2025_08_09_alis-concept","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"人工学習知能システム：ALIS構想"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年8月9日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本記事は、人工学習知能システム（ALIS）という、先天的学習（ニューラルネットワークの内部学習）と後天的学習（外部知識の活用）を統合した新たなAIシステム構想について解説しています。現在の生成AIは主に先天的学習に依存していますが、ALISはこれに加えて、再利用可能な知識の抽出、保存、選択、利用を核とする後天的学習プロセスを導入します。ALISは、知的プロセッサ、ナレッジストア、世界、ステートメモ","..."]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"人工学習知能システム"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"先天的学習"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"後天的学習"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",15]}]]}]]}],["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]]}]}]
16:["$","$L4","2025/08_08_Natural-Language-ML",{"href":"/ja/articles/2025_08_08_natural-language-ml","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"自然言語機械学習"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年8月8日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本記事では、大規模言語モデル（LLM）を活用した「自然言語機械学習」という新しい機械学習のパラダイムについて解説する。従来の数値ベースの機械学習が大量のデータと反復的な学習、前処理を必要とするのに対し、自然言語機械学習はLLMの自然言語処理能力を利用することで、学習効率を劇的に向上させることを目指す。基本モデルとして、LLMとナレッジベースを組み合わせ、入力文とLLMの回答、正誤判定結果をナレッジ","..."]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"自然言語機械学習"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"大規模言語モデル"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"数値ベース機械学習"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",16]}]]}]]}],["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]]}]}]
17:["$","$L4","2025/08_06_Micro-VM-Intelligence",{"href":"/ja/articles/2025_08_06_micro-vm-intelligence","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"マイクロ仮想知能としてのアテンションメカニズム"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年8月6日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本記事は、生成AIのブレークスルーとなったトランスフォーマーモデルの核心技術であるアテンションメカニズムについて、その機能と「仮想知能」という概念との関連性を論じている。アテンションメカニズムは、自然言語処理において、ある単語を処理する際に文中の他のどの単語に注意を向けるべきかを学習することで、代名詞や指示語の指す対象の特定、長文における文脈の維持を可能にする。これは、処理に必要な単語以外をマスク","..."]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"アテンションメカニズム"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"トランスフォーマー"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"Attention is All You Need"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",17]}]]}]]}],["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]]}]}]
18:["$","$L4","2025/07_28_Liquidware-Allrounder",{"href":"/ja/articles/2025_07_28_liquidware-allrounder","className":"group block bg-white rounded-lg shadow-sm hover:shadow-lg transition-all duration-200 p-6 border border-gray-200 h-full","children":["$","div",null,{"className":"flex flex-col h-full","children":[["$","div",null,{"className":"flex-1","children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 group-hover:text-blue-600 transition-colors mb-3 line-clamp-2","children":"リキッドウェア時代の全方位エンジニア"}],["$","p",null,{"className":"text-sm text-gray-500 mb-3","children":"2025年7月28日"}],["$","p",null,{"className":"text-gray-600 text-sm line-clamp-4 leading-relaxed mb-4","children":["本稿は、生成AIの進化がソフトウェア開発のあり方を根本から変え、「リキッドウェア」の時代へと移行する様相と、それに伴って求められる「全方位エンジニア」の役割について論じている。生成AI、特に大規模言語モデルは、プログラミング能力を飛躍的に向上させ、従来は専門家しか行えなかったコード生成を、人間との協働により容易に実現可能にした。これにより、開発者だけでなく、エンドユーザー自身が生成AIに指示を与え","..."]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-4","children":[[["$","span","0",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"生成AI"}],["$","span","1",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"大規模言語モデル"}],["$","span","2",{"className":"inline-block px-2 py-1 bg-blue-50 text-blue-700 text-xs rounded-full","children":"プログラム生成"}]],["$","span",null,{"className":"inline-block px-2 py-1 bg-gray-100 text-gray-600 text-xs rounded-full","children":["+",17]}]]}]]}],["$","div",null,{"className":"text-blue-600 text-sm font-medium group-hover:text-blue-700","children":"続きを読む →"}]]}]}]
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
8:null
19:I[8175,[],"IconMark"]
a:{"metadata":[["$","title","0",{"children":"#大規模言語モデル | katoshiの研究ノート"}],["$","meta","1",{"name":"description","content":"「大規模言語モデル」タグが付いた記事一覧。"}],["$","meta","2",{"name":"author","content":"katoshi"}],["$","meta","3",{"name":"keywords","content":"AI,ソフトウェア開発,システム設計,生命科学,博士,エンジニア,研究,思考法,シミュレーション思考,リキッドウェア,フレームワーク設計,仮想知能"}],["$","meta","4",{"name":"creator","content":"katoshi"}],["$","meta","5",{"name":"publisher","content":"katoshiの研究ノート"}],["$","meta","6",{"name":"robots","content":"index, follow"}],["$","meta","7",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","8",{"rel":"canonical","href":"https://katoshi-mfacet.github.io/ja/tags/large-language-model/"}],["$","meta","9",{"property":"og:title","content":"#大規模言語モデル | katoshiの研究ノート"}],["$","meta","10",{"property":"og:description","content":"「大規模言語モデル」タグが付いた記事一覧。"}],["$","meta","11",{"property":"og:url","content":"https://katoshi-mfacet.github.io/ja/tags/large-language-model/"}],["$","meta","12",{"property":"og:site_name","content":"katoshiの研究ノート"}],["$","meta","13",{"property":"og:locale","content":"ja_JP"}],["$","meta","14",{"property":"og:type","content":"website"}],["$","meta","15",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","16",{"name":"twitter:creator","content":"@katoshi_mfacet"}],["$","meta","17",{"name":"twitter:title","content":"#大規模言語モデル | katoshiの研究ノート"}],["$","meta","18",{"name":"twitter:description","content":"「大規模言語モデル」タグが付いた記事一覧。"}],["$","link","19",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x32"}],["$","$L19","20",{}]],"error":null,"digest":"$undefined"}
f:"$a:metadata"
