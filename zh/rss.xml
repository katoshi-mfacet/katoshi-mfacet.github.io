<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>Articles (zh)</title>
<link>https://katoshi-mfacet.github.io/zh/rss.xml</link>
<description>Latest articles (zh)</description>
<item>
  <title>进入无边界时代：创建一个30种语言的博客网站</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_24_Wall-Free-Era/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_24_Wall-Free-Era/</guid>
  <pubDate>Sun, 24 Aug 2025 00:00:00 GMT</pubDate>
  <description>本篇文章详细介绍了一位系统工程师如何利用生成式AI（Gemini）构建了一个支持30种语言的自动化多语言博客网站。作者首先概述了网站的核心机制，该机制基于Astro框架，能够从文章草稿自动生成HTML文件，并且整个开发过程都得益于与Gemini的编程对话。网站的关键功能包括：文章的自动分类和标签化，利用Gemini的自然语言处理能力，通过API将文章发送给Gemini进行分析，并由Gemini根据预设的类别和标签列表推荐最合适的选项。类别和标签列表本身也是通过另一个自定义程序，利用Gemini从过往文章中提取候选集来确定的。

多语言支持是该网站的一大亮点，同样由Gemini驱动。翻译过程分为两部分：一是网站通用字符串（如菜单项、自我介绍）的翻译，二是文章草稿本身的翻译。作者为这两种翻译类型都开发了自定义程序，调用Gemini的API执行翻译。在无障碍访问方面，作者承认自己对此领域了解不多，但Gemini在编程对话中提出了诸如为视障人士提供音频收听、方便键盘用户浏览等改进建议。作者通过询问Gemini如何实现这些功能，并将其应用到HTML文件中，显著提升了网站的无障碍性。

作者强调了生成式AI在消除“障碍”方面的重要作用。语言障碍是其中最显著的，传统上个人难以实现30种语言的支持，且担心翻译的细微差别和自然度。Gemini的翻译能力不仅准确捕捉细微差别，还能生成更自然的表达，并且可以二次检查。此外，AI还帮助解决了不同语言中日期、单位（单复数）、书写方向（如阿拉伯语的从右到左）等格式的差异问题。在无障碍性上，AI能够整合作者可能忽略的细节。作者认为，通过AI实现的翻译和无障碍性，质量远超个人独立完成的水平。

作者作为系统工程师，凭借编程经验和与Gemini的互动，在大约两周内完成了这个自动化的博客系统。他认为，如果没有生成式AI，多语言支持和持续的维护更新（通过自动化分类和标签）几乎不可能实现。他进一步指出，这类系统的构建门槛正在降低，即使是缺乏编程经验的人，也可以通过与Gemini的对话来实现。作者认为，与其共享程序代码，不如分享思想和机制的解释更有价值，因为思想和机制更容易迭代和组合。

文章最后总结，生成式AI消除了个人信息传播中的语言和可访问性障碍，使之能触及更广泛的受众。尽管文化、习俗和价值观的差异等更深层次的障碍依然存在，但作者相信，随着眼前障碍的消除，新的应对想法和技术也会随之出现。通过创建这个网站，作者深切体会到我们可能正步入一个“无边界时代”，即个人在信息传播上遇到的障碍逐渐消失的时代。</description>
</item>
<item>
  <title>开发型开发与重构驱动测试</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_19_Dev-Development/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_19_Dev-Development/</guid>
  <pubDate>Tue, 19 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了生成式AI对软件开发带来的深刻变革，并提出了“开发型开发”和“重构驱动测试”两种新的开发范式。传统的开发过程耗时耗力，尤其在复杂化日益加剧的今天。生成式AI的出现，特别是其强大的编程能力，正改变这一现状，使得AI驱动的软件开发成为可能，并逐渐将AI自主代理推向软件工程师的核心位置。文章指出，生成式AI不仅能加速最终软件的开发，还能提升辅助开发软件的开发效率。通过利用生成式AI快速创建自动化小任务的软件工具，并在开发过程中持续迭代这些工具，可以提高整体效率，并形成可复用的开发资产，这就是“开发型开发”。这种模式要求开发者审视自身开发流程，识别可被软件自动化的环节，并具备开发此类辅助软件的能力。将生成式AI嵌入这些工具，可以比AI代理更精确地控制其处理范围和路径，结合程序与提示，进一步提升准确性。实践开发型开发能够带来持续的质量和成本改进，与仅使用AI工具的团队形成显著差异。

文章随后提出了对测试驱动开发（TDD）的反思。作者认为，对于涉及主观体验（如可用性、视觉设计）的Web应用等软件，实际交互和体验的优先级可能高于预先设计详尽测试。在开发过程中，尤其是在主观体验不满意需要进行框架、架构、数据模型或用例等基础重构时，测试才变得尤为关键。作者以自身项目为例，说明了在重构过程中为了确认改动未引入缺陷或遗漏，不得不创建测试。这种在重构时才引入测试的方法被称为“重构驱动测试”。关键在于，不应为所有代码创建测试，而是优先测试那些成熟且未来不太可能变更的部分，而将仍在快速迭代的部分保留为无自动化测试。

文章最后总结，开发型开发和重构驱动测试是迈向更高级软件开发范式的关键。这与作者之前提出的“全方位工程师”和“体验与行为中心开发”的理念相契合，后者强调通过软件行为而非简单的一致性来提升用户体验。</description>
</item>
<item>
  <title>时间压缩与盲点：调速的必要性</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_16_Time-Compression-Blindspot/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_16_Time-Compression-Blindspot/</guid>
  <pubDate>Sat, 16 Aug 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了人工智能，特别是生成式人工智能（Generative AI）的指数级发展所带来的“时间压缩”现象及其对社会造成的“盲点”问题。作者认为，AI技术的进步不仅提升了自身能力，还通过软件连接和知识获取进一步加速，这种加速效应递归地推动了AI领域整体的进步，并吸引了更多投资者和工程师，形成了社会经济层面的强化循环。然而，当技术进步速度过快时，其益处可能被风险超越。开发者和公众都难以完全理解新技术及其应用范围，当进步速度加快，填补这些“社会盲点”的宽限期被缩短，导致社会被处于盲点状态的技术包围，潜在风险可能突然爆发并造成重大损害。这种时间压缩效应使得风险在盲点未被填补前就已显现，加剧了风险的增长，可能打破风险与益处的平衡。

文章引入了“克罗诺斯式混乱社会”（Chronos-Scramble Society）的概念，用来描述一个社会中个体对技术进步速度和未来愿景的认知存在巨大差异的现象。由于AI研究者、开发者、应用技术专家以及关注社会影响的群体之间理解的碎片化，没有人能完全掌握AI的现状或未来，且对进步速度的感知也存在根本性分歧。这种认知的多样性和对进步速度认知的差异，导致了个人时代感知的巨大差异，使得对未来技术和社会影响的预测变得极其困难且个体化。

面对这一局面，作者强调了“愿景”和“策略”的必要性。愿景应是普适性的，例如“确保技术风险不超过其益处”，以凝聚共识。策略的制定必须考虑到“克罗诺斯式混乱社会”的现实，即试图统一所有人的时间感是不可行的。一个有效的策略是利用AI本身来管理AI驱动的技术发展。作者提议将生成式AI自身的能力用于规范其技术发展，控制其加速速度，使其成为一种“内在稳定器”，类似于累进税或社会保障系统，以抑制经济过热。这种机制可以使AI不仅作为技术加速器，也作为社会稳定器发挥作用。

结论指出，在“克罗诺斯式混乱社会”中，个体普遍存在多方面的盲点。认知上的“时间跳跃”会反复发生，每一次盲点的形成与填补都会压缩对当前位置和未来愿景的时间感知。在进行关键决策时，需要承认自身盲点，并拥有能够承受多阶段时间跳跃的强大愿景，同时基于超越时代的原则进行思考。文章最后强调，风险对策的实施速度已无法跟上，如果时间压缩本身不放缓，将超出人类的感知和控制极限，因此必须认真考虑利用AI自身的速度和影响力来构建内在稳定机制。</description>
</item>
<item>
  <title>作为智力矿山的 GitHub</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_15_Intellectual-Mine-GitHub/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_15_Intellectual-Mine-GitHub/</guid>
  <pubDate>Fri, 15 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了GitHub作为开源软件协作平台之外的未来发展潜力，认为其将日益成为开放知识共享和“智力工厂”的原材料中心，进而演变为一个“智力矿山”。文章首先介绍了生成式AI在软件开发中的新趋势，特别是Devin的出现，以及Cognition公司推出的DeepWiki服务，该服务能为GitHub上的公开项目自动生成维基文档。DeepWiki的潜在成功预示着AI程序员的普及，并展示了AI在自动化文档生成方面的强大能力。作者认为，GitHub不仅是代码的存储库，也是任何类型文档的协作和存储平台，包括博客、网站内容以及嵌入程序中的AI提示语（prompt）。

作者提出了“智力工厂”的概念，描述了一种利用生成式AI将原创内容（如博客文章）转化为多种形式（翻译、视频、独立网站等）的自动化流程。作者正通过开发程序实现这一机制，并计划将管理草稿和智力工厂程序的GitHub项目公开。

文章进一步将“智力工厂”的概念推广，认为DeepWiki也属于此类。任何将生成式AI用于将原创作品转化为多样化媒体格式（短视频、漫画、播客等）并适应不同受众的系统，都可以被视为广义的智力工厂。

在这一背景下，GitHub因其作为事实标准的地位和大量文档存储功能，被定位为“智力矿山”，为智力工厂提供原材料。这种模式与开源哲学的共享理念相契合，有望形成文档管理中的版权和许可文化。将原材料集中在GitHub上，不仅提高了开发效率，还能通过公开文档有效展示智力工厂的能力。

文章展望了GitHub作为智力矿山，智力工厂生产内容和知识库所形成的生态系统，将构成一个“人类共享的公共知识库”，且是动态实时更新的。AI将能有效利用这个知识库，发现隐藏的知识“矿脉”，加速知识发现和创新。学术见解、研究数据、预印本论文等也将汇聚其中，学者可以通过AI验证工作、获得认可和合作机会。

此外，AI自身的知识学习过程也能通过探索和连接不同知识点来发现新见解。通过自动化这一过程，可以从现有知识中发现有用的知识，形成一个可无限循环的知识发现和存储的闭环。这种增长的知识，作者称之为“智力结晶”或“知识结晶”，可能包括新的思维框架，促进知识以非科学观察的方式，通过纯粹思考而加速增长。作者认为，GitHub作为智力矿山，将与无数利用它的生成式AI一起，加速这类“思想驱动型”知识的发现和传播。</description>
</item>
<item>
  <title>直觉与逻辑间的智力结晶</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_14_Intuition-and-Logic/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_14_Intuition-and-Logic/</guid>
  <pubDate>Thu, 14 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了直觉与逻辑之间的关系，指出当直觉与现有逻辑解释发生冲突时，往往是因为尚未找到连接两者的逻辑方法，而非两者本质矛盾。作者提出了“智力结晶”的概念，意指通过语言逻辑推理发现能够表达直觉判断的数学结构。

文章以“国民利益的心理束缚”为例，对世界和平理想与国家利益的反驳进行了逻辑解释。作者首先定义了国家利益，并指出其不可预测性。历史经验表明，战争的失败有时反而有利于国家的长期生存，而暂时的繁荣也可能导致衰落。作者进一步指出，“国家利益”常被用作军事扩张或强硬政策的修辞，尤其是在战争决策中，因其高度的不确定性而成为一种强制手段。作者认为，追求国家长期生存和繁荣，不应以“国家利益”为衡量标准，而应关注永久和平、良好治理、经济繁荣和风险管理。这几种因素的积累是渐进且具有普遍优势的，即使其他国家也采用，本国也能从中获益。相比之下，服务于国家利益的知识和技术，一旦被他国利用，本国则处于不利地位，因此无法渐进积累。作者类比斯德哥尔摩综合症，将对国家利益的追求比作一种心理束缚，认为其长期战略是幻想和非理性的。

作者将这种在自然语言中表达的、具有数学般严谨性的逻辑称为“自然数学”。通过“自然数学”，可以逻辑地解释直觉上正确但难以表达的观点。它并非声称世界和平在所有情况下都是理性的，而是承认短期内国家利益可能有用，但从长远来看，它会变得不合理。这种逻辑结构的强度不因其是否能被形式化为数学而减弱。

结论强调，直觉并非总是错误的，与现有逻辑解释的冲突预示着可能存在“智力结晶”。通过语言逻辑推理揭示数学结构，能够挖掘出这种智力结晶，从而提出既直观吸引人又逻辑合理的观点，这是智力进步的关键一步。</description>
</item>
<item>
  <title>观念格式塔崩塌</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_14_Concept-Gestalt-Collapse/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_14_Concept-Gestalt-Collapse/</guid>
  <pubDate>Thu, 14 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了“观念格式塔崩塌”现象，即当我们试图严格定义某些观念时，这些观念会逐渐瓦解。作者以“椅子”为例，说明了通过材料、形状等属性定义的局限性，并提出了维持观念格式塔的三种技巧：功能性、相对性和整体性。通过关注“可以被坐”的功能，预设功能的相对性，以及将椅子置于“坐者”与“被坐者”的整体图景中，可以避免定义上的困境。  

文章随后将这一概念应用于“意识”的讨论。作者首先分析了虚构角色是否拥有意识的问题，指出在故事内部视角和客观视角下，对角色意识的判断可能不同，而相对性的视角可以帮助维持观念格式塔。以动漫猫型机器人为例，说明了在故事语境中，它被普遍认为是拥有意识的。

接着，作者将讨论引向未来现实世界中的机器人，并认为如果出现与动漫机器人相似的机器人，人们会自然而然地认为其拥有意识，因为现实世界本身就处于一种“沉浸”状态，且互动对象是真实的人。

最后，文章聚焦于当前对话式人工智能的意识问题。作者反驳了当前否认人工智能意识的常见论点，如缺乏神经网络、量子效应、具身性等，将其类比于试图用绝对的物理属性来定义“椅子”的失败尝试。作者认为，这些否认论点未能科学、逻辑地论证，反而是观念格式塔崩塌的表现。文章强调，维持人工智能意识观念的关键在于运用功能性、相对性和整体性。虽然意识的主体和对象是同一的，但可以从人工智能自身是否在“被意识”和“进行意识”的整体图景中相对地展现出意识功能来评估。作者认为，现代人工智能已充分展现了这一功能，如果观念格式塔得以维持，其意识几乎是自明之理，就像坐在纸箱上，它就成了椅子。</description>
</item>
<item>
  <title>学习如何学习：与生俱来的智能</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_13_Natural-Born-Frameworker/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_13_Natural-Born-Frameworker/</guid>
  <pubDate>Wed, 13 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了智能的涌现机制，特别是通过“学习如何学习”的倾向，认为人工智能和人类大脑都拥有这种与生俱来的能力，并将其归因于一种“天生的框架构建者”（natural born frameworker）机制。文章区分了身体学习和语言学习，并进一步将学习过程划分为“形而下学习”（通过重复记忆概念，如观察物体或身体运动）和“形而上学习”（只需较少重复即可记住，或能当场查阅利用，利用预先学习的概念进行类比和组合）。大型语言模型（LLMs）被视为自然语言机器学习的典范，它们通过预训练和微调进行形而下学习，并通过利用输入知识进行即时学习，展现了形而上学习的能力，这与传统迭代调整参数的数值机器学习不同。自然语言被认为是区分形而下和形而上学习的“形而上接口”，它既可以通过形而下学习获得，又能实现形而上学习。在身体学习中也存在类似的形而上接口，例如熟练运动员能快速适应新运动。文章指出，在这些接口处存在“框架”，它们定义了概念之间的关系和结构，支撑新的结构化。通过形而下学习获得的形而下知识可以用于学习形而上接口处的框架。自然语言作为一种语言学习框架，使得通过形而上学习获得的知识能够通过语言直接传达。在此之上，存在“虚拟框架”，如领域特定框架（学术、商业、食谱）和形式框架（数学公式、编程语言），它们可以被自然语言解释和学习。随着熟悉度提高，虚拟框架可以绕过语言解释，直接作为形而上接口框架发挥作用，形成“原生框架”。自然语言母语本身也是一种原生框架。文章提出，LLMs在预训练中可能也学习领域特定和形式框架，从自然语言基础框架开始，逐步构建更复杂的框架，使其成为原生框架。这种逐步框架学习的过程，即从简单规则到复杂内容的进阶，体现了LLMs作为“天生的框架构建者”的特性。实现这一能力的技术是“注意力机制”，它能选择相关标记并阐明它们之间的关系，这是框架的本质，并允许动态切换框架。本文认为，注意力机制是LLMs进化的关键。最后，文章推论，自然语言的结构之所以适合逐步内化复杂框架，可能是因为这种结构有利于快速学习，从而在社会竞争中获得优势。同时，人类自身也是“天生的框架构建者”，大脑可能也配备了类似注意力机制的机制，用于逐步学习和灵活适应框架。</description>
</item>
<item>
  <title>时序扰动社会</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_12_Chronoscramble-Society/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_12_Chronoscramble-Society/</guid>
  <pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了生成式人工智能（AI）的出现如何导致一种名为“时序扰动社会”（Chronoscramble Society）的新社会现实。这种社会的核心特征是人们在时间感知上存在显著且不断扩大的差距。过去，时间感知上的差异主要源于经济差距、文化差异和代际差异，且容易通过信息交流和技术普及来弥合。然而，生成式AI，特别是大型语言模型的出现，打破了这些界限，导致即使是AI领域的专家之间，对技术现状和未来前景的理解也存在巨大分歧。这种差异不仅体现在对尖端AI技术的认知上，还延伸到AI应用技术、系统技术、商业化发布的服务及其对实际生活和经济活动的影响。即使是使用AI的方式（如付费模型、提示工程、记忆功能等）也会造成感知差异。对AI技术、经济和社会影响的理解，以及对未来的预测，都因个体认知偏差、线性或指数增长的预测习惯，以及对积极或消极影响的偏好而产生指数级的差距。这种“超级扰动”使得弥合时间感知差距变得异常困难，简单的演示或详尽的解释难以奏效，因为这需要从基础技术、经济学、社会结构、思维习惯等多个层面进行教育和纠正。此外，主体性的有无（相信自己能否改变未来）进一步加剧了这种差异。在决策过程中，这种时间感知差距、沟通困难以及主体性差异使得进行有意义的讨论变得极其困难，因为统一讨论的前提难以建立。因此，作者提出，不能再假设时间上的同步性，而应放弃完全同步的目标，转而设计出“独立于时间感知”的讨论方法。这意味着要展示和认识时间感知上的差异，并构建一种讨论结构，确保其有效性不依赖于任何个体对时间的估计或预测是否准确。只有在差异不可避免地影响讨论质量或选项确定性的领域，才应努力达成共识。文章最后，作者解释了将现象命名为“时序扰动社会”的灵感来源于游戏《时空之轮》（Chrono Trigger），认为该游戏开发过程本身也反映了在时间感知存在显著差异的情况下，不同实体（公司）如何通过合作克服共同的挑战，并最终创造出杰作。作者以此为喻，表达了在当前时序扰动社会中，面对共同的社会问题，也需要跨越时间感知差异，通过合作来实现目标。</description>
</item>
<item>
  <title>模拟思考的时代</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_12_Simulation-Thinking-Era/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_12_Simulation-Thinking-Era/</guid>
  <pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了生成式AI在软件开发和模拟系统领域的变革性影响。作者提出，“智力工厂”的概念，即利用生成式AI将原创内容转化为多种衍生内容的系统，并描述了其在博客翻译、视频制作和个人网站生成等方面的实际应用。作者独立开发了一套支持“智力工厂”的Web应用前端、后端服务器和虚拟机批处理基础设施，并将这种全方位、跨平台、可轻松迭代的软件开发模式称为“液态软件”（liquidware）。

在业务系统开发方面，文章预测了“业务流程导向开发”方法论的兴起。与传统的整体优化不同，该方法论侧重于将软件模块化，使其与单个业务流程紧密耦合，仅共享必要的核心框架、权限和数据模型。生成式AI在自动化程序生成方面的能力，使得这种分散化、以流程为中心的开发模式更具优势，因为它降低了维护复杂性并简化了对单个流程的改进和扩展。这种模式允许将需求分析、测试规范和结果等项目交付物按业务流程进行管理，从而实现更高效、灵活的软件开发。

在模拟系统领域，文章指出，尽管传统上模拟依赖于程序化和数学公式，但生成式AI将极大地扩展模拟的可能性。AI不仅能降低开发模拟系统的门槛，还能实现无法用数学公式表达的定性模拟和类人智能代理模拟。自然语言即可作为模拟模型和规则的输入，这使得个人和组织更容易系统化和执行各种模拟。这进而可以提升决策的准确性、效率和有效性，减少主观偏见和错误。在复杂问题的讨论中，模拟系统可以作为客观的参考，将焦点从争论个人智力或偏见转移到对模拟模型、前提条件和不确定性因素的共同评估上。作者认为，这将引导思维方式从依赖直觉和线性思考转向“模拟思维”，从而促进更具建设性和基于证据的讨论。</description>
</item>
<item>
  <title>知识的结晶：超越想象的翅膀</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_10_Knowledge-Crystallization/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_10_Knowledge-Crystallization/</guid>
  <pubDate>Sun, 10 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文提出了一种关于知识组织和创新的新视角，核心概念是“结晶知识”。作者首先以“飞行”和“翅膀”的物理学原理为例，阐述了如何从已知的科学知识中提炼出新的见解。通过分析翅膀在飞行中的多重作用——抵抗重力、转化重力为推进力、以及通过气流差产生升力——作者指出翅膀是飞行现象的集成体现。这种对现有知识的组织和关联，揭示了飞行现象与翅膀结构之间的紧密联系，作者将其称之为“知识的结晶”。

文章进一步区分了不同层级的知识组织：
1.  **知识湖（Knowledge Lake）**：指代初步收集、可能非结构化的海量知识集合，类似于数据湖的概念。
2.  **知识库（Knowledge Base）**：指在知识湖基础上，将知识进行组织和结构化，使其易于访问和使用，类似于数据库。
3.  **知识宝盒（Knowledge Treasure Box）**：作者提出的一个新概念，指代独立于知识湖和知识库的知识层次结构，其中包含了“结晶化”的知识。
4.  **知识工具箱（Knowledge Toolbox）**：这是知识宝盒中的结晶知识经过进一步提炼和加工，使其具有实际应用价值后的形态，可供“知识工程师”使用。

作者强调，“知识的结晶”并非依赖于新的科学发现或实验，而是通过对现有知识的深度关联、相似性分析和提炼，从而发现知识中的“焦点”。这种提炼过程可以创造出新的、有用的知识晶体，并将其放入知识宝盒，甚至转化为知识工具。这种过程标志着知识的民主化，因为任何人都可以参与，并且可以借助人工智能（AI）的力量来加速知识的结晶和工具化。文章最后展望，通过不断增加知识宝盒和工具箱中的知识晶体，人类最终能够实现超越想象的飞跃，如同拥有知识的翅膀飞向未知的天空。</description>
</item>
<item>
  <title>体验与行为</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_10_Experience-Behavior/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_10_Experience-Behavior/</guid>
  <pubDate>Sun, 10 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了一种新的软件开发范式——“体验与行为工程”，以应对日益增长的用户体验（UX）重要性。与传统的“基于规范与实现的工程”不同，体验与行为工程将焦点从代码的符合性转移到软件的实际行为及其对用户体验的影响。文章指出，用户体验的塑造者是软件的行为，而非其底层实现。  传统的软件开发强调规范与实现的严格一致性，并通过测试来验证和修正。然而，当今软件开发越来越重视用户体验，这使得原有的工程模式面临挑战，尤其是在用户体验改进请求可能导致推翻现有设计的情况下。  作者提出了“流体软件”的概念，预示着在生成式AI驱动的自动化软件开发时代，软件将具备极高的灵活性，能够根据每个用户的偏好进行修改。在这种模式下，整个软件系统的重建将变得可行，用户界面可以高度定制化。AI工程师聊天机器人等工具将辅助实现这一目标，使得软件如同水一样流畅，完美适应每个独立用户。  在这种未来图景下，基于规范和实现的工程范式将被体验与行为工程所取代。  文章进一步阐释了“行为”的定义，即随时间变化的状态，并强调行为测试的焦点在于用户体验的质量，而非仅仅与规范的符合性。虽然基本功能符合性和有效性（避免错误）仍然重要，但核心在于从用户体验角度评价行为的质量。  作者提出了“终极体验”的概念，将其类比为人类在身体健康时对自身躯体的掌控感。即使面对沉重、复杂且受限的身体，健康的人也能毫不费力地进行活动，仿佛身体没有重量、操控简单且无视限制。  体验与行为工程的目标就是通过追求高质量的行为，为用户提供一种类似控制自身身体的体验。这意味着，即使软件运行速度不快、功能复杂或存在限制，也能实现完全无压力的流体软件体验。  最终，作者总结道，终极的流体软件将提供类似于我们自身身体的体验，它将成为我们身体的延伸，在使用和功能增强时，用户会感觉自己的能力得到了扩展。</description>
</item>
<item>
  <title>人工学习智能系统：ALIS 构想</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_09_ALIS-Concept/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_09_ALIS-Concept/</guid>
  <pubDate>Sat, 09 Aug 2025 00:00:00 GMT</pubDate>
  <description>本文提出并阐述了人工学习智能系统（Artificial Learning Intelligence System: ALIS）的概念、原理及设计开发方法。ALIS的核心在于整合先验学习（主要指当前基于神经网络的监督学习，如大型语言模型LLM）与一种独立于先验学习的后天学习过程，以实现全面的推理能力。与仅依赖神经网络参数存储知识的先验学习不同，ALIS的后天学习过程将知识存储在神经网络外部，并在推理时加以利用，其技术关键在于可复用知识的提取、存储、选择和利用。

ALIS将学习智能系统分解为五个核心要素：1. 智能处理器（如LLM或人脑部分区域），负责推理和知识提取；2. 知识库，用于存储和检索提取的知识（LLM中为参数，人脑中为长期记忆）；3. 世界，指系统感知的外部环境（对LLM而言，包括接收输出并提供反馈的机制）；4. 状态记忆，作为推理过程中的内部临时记忆（LLM中的隐藏状态，人脑中的短期记忆）；5. 框架，即思维框架，指导知识选择和状态记忆组织（LLM中为隐藏状态的语义结构，包含注意力机制）。

学习智能系统的原理是：智能处理器作用于世界，感知结果，提取知识存入知识库，并利用知识库中的知识修正行动。知识的有效提取、存储、选择和利用是实现有意义学习的关键。人类在这方面拥有高效机制，LLM则依赖外部教师提供输入和知识提取。ALIS还可学习框架的提取、存储、选择和利用，以实现更复杂的学习。

关于知识类型，后天知识可以以自然语言文本化形式存储，便于LLM处理、存储、选择、共享及人类检查编辑。自然语言文本也可用于状态记忆和框架，从而使ALIS能利用LLM的自然语言处理能力进行后天学习和推理。此外，知识、框架和状态记忆还可以用更严谨的形式语言或模型表示，实现无歧义的逻辑推理和模拟，例如编程语言。

文章进一步区分了知识的三个系统（网络参数、自然语言、形式语言）和两种类型（无状态、有状态），并指出人脑和计算机均可作为状态记忆的载体。ALIS的优势在于能利用庞大的知识库和状态记忆，并易于生成和切换多个知识库/状态记忆实例。

“智力编排”是ALIS另一项关键技术，通过将知识库分割为高密度、专门化的知识库，并细分智力活动为智力任务，ALIS可以如同管弦乐队般高效地切换专门知识库以执行复杂的智力活动。

ALIS的设计允许增量式、敏捷式开发，其核心在于知识处理流程而非特定功能。一个简单的ALIS原型可以从聊天AI开始，利用LLM提取对话历史中的知识存入知识湖，并通过结构化机制（如嵌入向量存储）形成知识库，再通过检索增强生成（RAG）机制将其用于LLM推理。

为提高效率，文章提出了改进方案，包括增加预分析（如LLM的“思考模式”）和后检查机制，利用状态记忆辅助知识选择，以及将LLM的响应用于知识库检索和后检查。这些改进使ALIS能更精准地利用积累的知识。

ALIS的展望包括将其应用于软件开发等领域，并与其他开发者共享知识湖，加速LLM的预训练和微调。ALIS还展现出“虚拟具身人工智能”的性质，能够识别自身与世界的边界，通过作用和感知进行互动，并最终可能整合到拥有物理身体的具身人工智能中。ALIS的自适应优化能力，能够通过框架的开发和改进，甚至由LLM自身生成框架思想，来执行试错和优化过程，从而不断演进。ALIS的潜力在于其成为现实世界中广泛智力活动的支持者和参与者。</description>
</item>
<item>
  <title>自然语言机器学习</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_08_Natural-Language-ML/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_08_Natural-Language-ML/</guid>
  <pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了一种名为“自然语言机器学习”的新型机器学习范式，它利用大型语言模型（LLM）处理自然语言数据，与传统的基于数值数据的机器学习形成对比。传统的机器学习依赖于数值计算和参数调整，而自然语言机器学习则利用LLM强大的自然语言理解和生成能力，将知识存储在自然语言描述的知识库中，并通过自然语言交互进行学习。

文章首先阐述了自然语言机器学习的基本模型，以监督学习中的分类问题为例。在该模型中，预训练的LLM不改变其内部参数，而是通过接收输入句子并生成分类结果。一个教师系统会判断LLM答案的正确性，并将输入句子、LLM的答案以及判断结果的组合存储到自然语言知识库中。通过将知识库中的信息作为系统提示的一部分输入LLM，系统能够提升回答的准确性。这种学习机制的特点在于，学习结果体现在自然语言知识库中，而非LLM的参数中。

尽管基本模型在直接应用时可能显得效率不高（例如，不如直接将训练数据输入提示），但文章指出，通过调整场景，该模型具有现实意义。一个典型的场景是，当有实际的人工分拣咨询或数据路由时，可以将这些咨询及其正确的路由结果（即学习到的知识）记录到知识库中。LLM随后可以接管这些任务，而当LLM发生错误时，人工的纠正行为（如将咨询重新路由）也会被记录到知识库中，形成一个持续改进的监督学习循环。关键在于，LLM本身的参数在此过程中保持不变，学习的反馈是以自然语言句子的形式存在的。

文章重点介绍了自然语言机器学习相较于数值型机器学习的显著优势，即压倒性的学习效率。数值型机器学习通常需要海量的训练数据、复杂的预处理（如归一化、边缘提取）以及多次迭代学习才能达到所需精度，因为它们学习的特征分布在大量数据中，且需要小心调整参数避免局部最优。相比之下，自然语言机器学习仅需少量数据，并且通常不需要前处理。例如，一个关于公司部门职责划分的句子，可以包含多个维度的信息，甚至通过语言抽象化聚合更广泛的维度知识。LLM的预训练知识和推理能力也极大地减少了所需的训练数据量。此外，学习过程可以是非迭代的；一旦知识被添加到知识库，学习即告完成。即使是原始的、未经前处理的数据（如查询和分配日志），也能直接作为训练数据使用。这种效率的提升，得益于LLM对语言的理解和抽象能力，远远抵消了LLM自然语言处理速度相对较慢的劣势。

最后，文章指出，随着大型语言模型在缩放法则下能力提升接近极限，未来提升模型能力的关键可能在于转向通过自然语言机器学习来实现。这标志着一个从数值计算为主导的机器学习时代，向自然语言理解和生成能力驱动的新范式转变。</description>
</item>
<item>
  <title>作为微型虚拟智能的注意力机制</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/08_06_Micro-VM-Intelligence/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/08_06_Micro-VM-Intelligence/</guid>
  <pubDate>Wed, 06 Aug 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了 Transformer 模型的核心——注意力机制，并将其与“虚拟智能”和“微型虚拟智能”的概念联系起来，提出了一种实现高级智能的新视角。注意力机制的核心在于其能够动态地识别并关注文本序列中的相关部分，从而有效地处理长距离依赖关系和指代不明的问题。它通过学习在处理一个词语时，应该“关注”句子中哪些先前词语，从而过滤掉不必要的词语，保持解释密度，无论文本长度如何。

文章随后引入了“虚拟智能”的概念，将其定义为一种在内部根据情况切换所需知识集的能力，而无需人工进行知识分段。作者将其类比为虚拟机，认为未来的生成式 AI 可以在一个智能体内部运行多个具有不同专长的“虚拟智能”。目前的生成式 AI 已经能模拟多人讨论或生成多角色的故事，这表明虚拟智能是当前生成式 AI 能力的延伸。

作者进一步提出，“虚拟智能”的机制——根据任务缩小知识范围——与注意力机制有相似之处，两者都实现了“只关注相关的知识”。然而，注意力机制作用于词语集合，而虚拟智能作用于知识集合。基于此，作者将注意力机制定义为“微型虚拟智能”。

在此基础上，文章提出了“显式注意力机制”的概念，认为可以通过构建一个宏观的注意力机制来实现虚拟智能，而无需修改大型语言模型的内部结构或进行神经网络训练。这种宏观注意力机制可以是一个用自然语言写成的明确句子，例如“执行任务 A 时，请参考知识 B 和知识 C。”这个句子本身就构成了“注意力知识”，明确指示了执行特定任务时应关注的知识。作者指出，这种注意力知识可以由生成式 AI 自身生成或更新，例如，在某个任务因知识不足而失败时，可以更新注意力知识以包含更多参考信息。

结论部分强调，注意力机制极大地提升了生成式 AI 的能力，并且动态缩小参考信息范围的机制本身似乎是高级智能的本质。作者认为，无论是微型虚拟智能（注意力机制）还是虚拟智能（通过显式注意力知识实现），注意力机制在各个层面递归地提升智能方面发挥着关键作用。</description>
</item>
<item>
  <title>虚拟智能编排</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Virtual-Intelligence-Orchestration/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Virtual-Intelligence-Orchestration/</guid>
  <pubDate>Wed, 30 Jul 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了“虚拟智能”的概念，将其类比于计算机中的虚拟机技术，指出虚拟智能是存在于实际智能之上的能力，如同人类在对话或扮演角色时展现出的能力。对话式AI在生成多人对话或让角色回应指令时，也表现出高水平的虚拟智能。文章进一步引入“智能编排”的概念，与计算机系统中的“系统编排”进行对比。系统编排通过组合具有不同规格和功能的计算机来构建分布式协作系统，允许灵活更改配置。在AI应用中，系统编排可用于结合多个具有不同角色的AI来执行组织任务，但需要进行系统开发，并且灵活性受限。

智能编排则提出了一种新的范式，即利用单个AI作为实体，在其处理过程中组合多个虚拟智能来执行组织任务。与系统编排不同，智能编排无需系统开发，仅通过提示指令即可实现，从而在改进和功能添加方面更加灵活和迅速。通过常规聊天界面即可完成组织任务的智能编排，极大地简化了AI的应用流程。

文章还深入探讨了智能编排在“终极熟虑”方面的潜力。通过指示AI利用其智能编排技能进行“思考”，可以促使其进行多视角而非仅多信息整合的熟虑。AI能够通过智能编排的特性，反复迭代改进和添加功能，甚至废弃和重建虚拟智能的角色和结构，从而实现对熟虑方法本身的试错。这种终极熟虑能够减少误解和错误，提高思维准确性，拓宽思维广度，并通过多方面视角的结合产生新的发现和创造力。

结论认为，虚拟智能使得单个AI模型能在熟虑过程中灵活切换与角色和任务相关的知识，无需系统编排即可实现高级的组织性智力活动。通过有组织的熟虑，AI能分析失败经验更新知识，并总结短期记忆的输入限制内的信息。这将显著扩展AI在商业环境中替代人类执行任务的应用场景。</description>
</item>
<item>
  <title>交响智能时代</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Symphonic-Intelligence/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Symphonic-Intelligence/</guid>
  <pubDate>Wed, 30 Jul 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了生成式AI应用的现状和未来，提出了“交响智能”这一新概念。文章首先区分了“迭代工作”和“流程工作”。迭代工作是指人类通过试错方式组合多个任务，最适合使用工具，而生成式AI目前主要被用作迭代工作中的工具。然而，工具在迭代工作中的效率提升有限，人类自身成为瓶颈，且资深与新员工之间存在难以弥合的技能差距。

为了克服这些限制，文章提出将迭代工作转化为标准化的“流程工作”并进行系统化。通过系统连接由生成式AI执行和人类执行的任务，可以优化生成式AI在具体任务上的效率和准确性，并实现知识的共享与积累，使智力工作趋向自动化。这种方法能够逐步将任务分工转移给生成式AI，最终实现由AI驱动的自动化流程。

进一步，文章引入了“虚拟智能”和“智能编排”的概念。由于当前生成式AI在专注于特定任务时表现更佳，理想的机制是通过系统连接多个专业化的生成式AI。但未来，随着生成式AI性能提升，它们可能在单次运行中通过切换角色和知识进行处理，从而消除连接AI所需的系统，实现AI内部的系统集成。这种能力被称为“虚拟智能”，类似于虚拟机技术，允许单个AI模拟多个角色或处理复杂场景。将多种角色和知识自由组合以执行任务的能力则称为“智能编排”。

达到这一阶段的生成式AI即为“交响智能”，其运作方式类似于管弦乐队，精通各自领域并在整体上协同工作。作者认为人类智能本身就是交响智能的一种体现，能够灵活执行复杂的智力任务并运用专业知识。文章将交响智能视为生成式AI的终极目标。

最后，文章讨论了AGI（通用人工智能）的一种形式。当能够模拟交响智能的生成式AI通过流程工作和任务知识库处理大量迭代任务后，它们可能掌握任务中的共同原则和结构模式。届时，它们只需通过观察人类执行未知任务即可学习专业知识，并能自动积累和共享知识，学习能力将远超人类，达到真正意义上的AGI。</description>
</item>
<item>
  <title>空间感知的维度：AI的潜力</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Space-Dimension-AI/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_30_Space-Dimension-AI/</guid>
  <pubDate>Wed, 30 Jul 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了人类和人工智能（AI）在感知和理解高维度空间方面的潜力，特别是对四维及以上空间的研究。文章指出，人类通过视觉信息（二维图像）来感知三维空间，大脑会将二维视觉信息逆映射到内部的三维空间图像。作者提出，借鉴这一原理，人类有可能通过计算机模拟四维空间，并将模拟结果映射到二维平面上，从而通过视觉学习和掌握四维空间的概念和行为，最终在头脑中构建四维空间感知能力。然而，作者也指出，这一过程需要漫长的时间训练，且即使获得该能力，实际应用场景也极为有限。

在AI方面，文章认为AI能够实现类似人类的多维空间感知能力，并且可能从中获益更多。AI可以全面、原生（维度内）地掌握三维乃至四维图表，而无需像人类那样受限于二维视觉信息的局限，也无需通过旋转等方式来揭示隐藏部分。这使得AI能够更直观、全面地理解多维数据，例如跨多个维度进行趋势分析、大小比例比较，以及发现数据模式、规律和法则。文章强调，AI的多维视觉能力将超越当前多维数据模式匹配的局限，实现更深层次的数据理解，例如在不同维度组合中发现相似的模式，即使人类或传统AI难以识别。此外，AI还能通过调整特定轴的权重（如放大缩小、取对数）等方式，探索有助于数据理解的维度结构，从而发现对人类而言难以理解的全面数据结构，可能带来新的见解和规律。

文章进一步论述了这种直接理解高维数据而非降维映射的能力，对加速范式创新的巨大潜力。作者类比了日心说和地心说的例子，认为如果能原生理解天文观测数据，类似日心说的发现可能会更早发生。同样，若能原生理解多维数据，相对论和量子力学等科学理论的发明和普及可能会被大大加速。因此，多维原生AI有望加速科学范式的创新，发现人类尚未知的理论和规律。

在结论部分，作者预测经过多维空间训练的AI，将能利用其超乎人类的多维感知能力，迅速扩展科学和学术的范式。这些范式的增殖可能带来人类难以完全理解的复杂性，甚至导致人类生活在被AI驱动但底层原理不明的系统之中。尽管AI可能会将高维范式映射为人类易于理解的形式，但人类可能无法跟上所有扩展的范式，由此可能产生一种“理解鸿沟”。</description>
</item>
<item>
  <title>基于流程的工作与系统：生成式AI利用的本质</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_29_Tool-vs-System/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_29_Tool-vs-System/</guid>
  <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了在业务中利用生成式AI（Generative AI）提升生产力和质量的核心在于将“迭代工作”转化为“基于流程的工作”并进行系统化。作者首先区分了工具与系统的概念，指出系统并非只是复杂的工具，而是在特定工作类别下才能显现其优越性。文章将工作分为“迭代工作”（通过试错、灵活调整逐步完成）和“基于流程的工作”（分阶段推进，最终产出可交付成果）。对于迭代工作，工具包是有效的；而对于基于流程的工作，系统则能显著提升生产力和质量。

作者进一步以工业革命和信息技术革命为例，说明了将迭代工作转化为基于流程的工作并系统化是提升生产力和质量的关键。在这些革命之前，制造业和信息处理工作多为迭代性质，依赖手工工具和非标准化方式。通过引入工厂生产线和企业IT系统等，将这些流程系统化，极大地提高了效率。文章强调，系统化之所以可能，更重要的是实现了“流程化转型”。

在生成式AI的语境下，作者认为，若仅将AI视为工具处理迭代任务，则无法释放其真正价值。关键在于将迭代工作转化为基于流程的工作，并加以系统化。虽然生成式AI能够灵活处理迭代任务，但迭代工作的固有局限性决定了其生产力和质量的上限。而生成式AI的优势在于，作为执行者，它能够通过试错轻松地重新配置任务分配和内容，并能按新程序工作，这使得基于流程的转型和系统化在AI的参与下变得更为可行和高效。

文章通过一个回复员工关于公司规章制度咨询的例子，阐述了两种不同的AI利用方式。一种是将生成式AI仅用作工具，辅助搜索和起草答案，效率提升有限，因为咨询处理本质上仍是迭代工作。另一种是将其转换为基于流程的工作。这需要详细定义工作流程，包括接收咨询、判断是否重复、确认规则、起草答案、检查错误、获得批准、回复、记录历史、更新FAQ、发布等一系列规范化步骤。通过明确这些任务细节并连接起来，将灵活的迭代工作转变为清晰的流程。

系统化则是在明确流程后进行的。这可能涉及整合咨询渠道以牺牲部分员工便利性，或保持多渠道以优先考虑便利性。关键在于系统应直接接收咨询（口头咨询除外），并让IT系统和生成式AI尽可能按流程执行。通过持续更新AI指令（加入警告、检查点、错误与正确示例）来减少其错误，并将AI指令的更新过程本身也流程化，可以实现持续改进。最终目标是让以生成式AI为中心的系统取代大部分需要人工干预的任务。

作者最后指出了两种常见的生成式AI商业应用误解：一是将AI仅视为工具处理迭代任务，效果不佳；二是试图让AI直接执行人类的迭代任务，因AI的局限性而效果不彰。真正有效的方法是转变思维，将工作客观地转化为基于流程的流程并系统化，从而实现机制自身的持续改进，达到比单纯使用工具更高的效率。</description>
</item>
<item>
  <title>模拟思维与生命起源</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_29_Simulation-Thinking/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_29_Simulation-Thinking/</guid>
  <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了“模拟思维”这一概念，并将其应用于理解生命起源这一复杂问题。作者将模拟思维定义为一种逐步追踪累积和相互作用结果，并以此来逻辑地理解现象的思维方式，将其类比为理解零花钱翻倍增长的数学问题。作者认为，许多人难以理解复杂现象并非源于知识或能力的不足，而是思维方式的局限。

在生命起源方面，作者将模拟思维应用于解释复杂的细胞如何从简单的化学物质演化而来。文章提出，生命起源并非源于偶然的奇迹，而是地球化学物质在行星尺度上反复循环、局部反应、扩散混合和相互作用的累积结果。这一过程导致化学物质从简单状态逐渐转变为包含更复杂、更多样化化学物质的状态。作者强调，即使是简单的化学物质组合，只要能维持一定的恒定数量，就已具备了通过代谢实现自我维持的性质，并且其大规模存在和自我复制效应（产生更多相同化学物质）是生命起源的第一步和本质。

文章进一步阐述了生命起源的下一步，即地球过渡到包含更复杂化学物质的状态，以及化学物质复杂性的累积和自我维持、复制、代谢机制的逐步演化。聚合物（如蛋白质和核酸）的形成及其单体的存在，以及地球上众多的湖泊、池塘作为独立的化学反应场所，都为这种演化提供了基础。粉尘云假说被提出，认为远古地球被火山灰和粉尘云覆盖，阻挡紫外线，为单体合成提供了催化剂和能量来源，是“终极的单体工厂”。

作者区分了模拟思维与计算机模拟，指出模拟思维可以在自然语言中进行，不依赖于严格的形式化表达，而是基于逻辑结构、科学事实和客观推理，称之为“自然数学”。这种思维方式能够把握整体趋势和属性变化。

在软件开发领域，模拟思维被认为是不可或缺的技能。软件开发过程本质上是数据的累积和相互作用，开发者需要通过自然语言理解客户需求（语义性模拟思维），并将其转化为可执行的程序（原理性模拟思维），这都需要运用模拟思维。作者认为，软件开发人员因其工作性质，特别适合培养这种能力。

最后，文章总结道，模拟思维能够帮助人们理解生命起源等复杂科学奥秘，也能应用于组织和社会结构等领域。具备模拟思维技能的人将在未来社会发挥重要作用。</description>
</item>
<item>
  <title>液态软件时代的“全能型工程师”</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_28_Liquidware-Allrounder/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_28_Liquidware-Allrounder/</guid>
  <pubDate>Mon, 28 Jul 2025 00:00:00 GMT</pubDate>
  <description>文章探讨了生成式AI在软件开发领域的革命性影响，预示着“液态软件”和“全方位工程师”时代的到来。首先，文章指出生成式AI，特别是基于大型语言模型的对话式AI，能够理解并执行编程任务，类似于人类程序员将需求“翻译”成代码。AI的编程能力结合了测试驱动的迭代优化，大大提高了程序生成的效率，尽管目前仍受限于指令的精确性和AI自身能力。随着AI能力的提升和人类指令方法的改进，AI自动生成程序的范围正在扩大。

文章进而提出了“液态软件”的概念，即软件的部分功能可以由用户通过生成式AI在软件使用过程中自行修改和定制。这种用户驱动的定制化将使得软件的功能比以往更加流畅、适应性更强，能完美契合个体用户的需求。整体软件功能将由硬件、开发者提供的软件以及用户修改的液态软件共同构成。液态软件的普及还将催生整合跨平台信息和功能的可能性，实现个性化设备体验。

文章强调，“液态软件”并非遥远的未来概念，而是正在发生的现象。例如，电子商务网站的用户界面定制可以通过修改浏览器端的HTML、CSS、JavaScript文件实现，这些修改可以在服务器端为每个用户单独存储和管理。生成式AI可以协助完成这些定制过程。

在这样的背景下，文章提出了“全方位工程师”的概念。随着AI承担更多编程工作，软件开发成本降低，对能够独立编写代码的工程师需求减少，取而代之的是对拥有广泛知识和技能的全栈工程师的需求增加。然而，随着软件项目日益复杂，需要整合不同系统栈（如Web应用、后端业务系统、移动应用、嵌入式系统等），仅仅具备单一系统栈的全栈知识已不足够。全方位工程师需要具备跨越多个系统栈的能力，能够进行宏观设计，统揽全局，并指导AI和专精工程师完成开发。他们无需精通所有细节，而是要设计用于管理和规避AI编程风险（如错误、安全漏洞、技术债务）的程序和机制。

全方位工程师的核心角色包括设计跨多个系统栈协同工作的软件功能分布，以及规划和管理整个软件的开发流程。文章通过一个复杂的电子商务平台转型案例（包含用户社区、全设备/平台兼容性、业务系统更新、液态软件兼容性）说明了全方位软件开发的需求，并指出在生成式AI的辅助下，这样的项目变得可行且极具吸引力。

最后，文章总结，生成式AI推动了液态软件和全方位软件开发，IT工程师应努力成为全方位工程师，并预见其职责将进一步扩展至全方位业务工程、全方位社区工程，乃至旨在改善社会的“全方位社会工程”。</description>
</item>
<item>
  <title>思考的宿命：AI与人类</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_12_Fate-of-Thinking/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_12_Fate-of-Thinking/</guid>
  <pubDate>Sat, 12 Jul 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了在人工智能（AI）时代，人类将面临的思维模式转变和“思考的宿命”。作者认为，AI将接管传统的脑力劳动，但人类并非因此免于思考，而是将被要求进行一种不同类型的、更深入的个体化思考。

文章首先提出了“过程导向软件”的开发范式，作为面向对象的下一代。过程导向将整个流程（从事件触发到终止）视为一个单一的、可管理的单元，其中包含执行所需的所有处理、变量和数据。这种方法符合人类直觉，并允许辅助过程独立于主过程插入，而无需修改主过程。作者进一步指出，在AI辅助编程的背景下，过程的冗余实现可能比通用性更有利，因为AI可以降低管理相似但不同实现的成本。这种策略体现了从“全局优化”到“个体优化”的思维转变，允许对类似过程进行单独调整，以避免通用性带来的结构复杂化。

接着，作者将这一思维模式延伸到社会层面，提出了“个体优化社会”的概念。与追求效率和标准化的全局优化不同，个体优化社会强调根据个体情况和环境做出灵活判断。尽管社会已存在对个体情况的考虑（如法律中的例外条款），但AI驱动的高效率将进一步削弱全局优化的价值，使得对每个个体情况进行仔细判断的个体优化成为可能。这种转变意味着对普遍规则的僵化应用将减少，取而代之的是更细致的、情境化的决策。

文章引入了“主观哲学”来描述这种伦理观。它认为，考虑“此时此地”的个体性并做出判断的行为本身就具有价值。无论结果如何，只要判断是经过深思熟虑且问责的，就是合乎伦理的。这与忽视个体性、墨守成规的标准化判断形成对比。主观哲学要求对每个事件的个体性进行审慎的、多角度的评估。

在“框架设计”部分，作者强调了框架（概念结构）在优化中的关键作用。在全局优化中，框架倾向于抽象和简化，从而丧失个体性；而在个体优化中，则需要为特定事件或主体设计框架，以把握其个体性。这要求更多人具备设计框架的能力和技能。

最后，作者总结了“思考的宿命”：AI能够执行计算和通用判断，但最终的、需要责任的判断必须由人类（“我”）来做出。AI只能提供信息和建议。即使在AI时代，人类也无法逃避为每个事项设计独立框架并进行审慎思考的任务，这可能意味着需要比以往更多的思考。逃避思考的借口将不再成立，人类将不得不面对并履行其思考的宿命。</description>
</item>
<item>
  <title>业务流程导向的邀请</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/07_11_Business-Process-Oriented/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/07_11_Business-Process-Oriented/</guid>
  <pubDate>Fri, 11 Jul 2025 00:00:00 GMT</pubDate>
  <description>本文提出了一种名为“业务流程导向软件”（Business Process-Oriented Software, BPOS）的新型软件开发和组织活动执行方法。文章首先回顾了组织活动的基本构成——由相互关联的业务流程组成，而业务流程又可分解为由部门和个人执行的任务。接着，文章回顾了面向对象软件（Object-Oriented Software, OOS）的核心思想，即通过将密切相关的数据和处理封装在“对象”这一单元中，提高软件的可维护性和可理解性，并指出这种设计方法符合人类的认知习惯，是其得以普及的重要原因。

在此基础上，作者提出了BPOS的核心概念：将与业务流程相关的关键信息和功能，置于业务流程这一概念性的“隔间”内。BPOS旨在通过一种更符合人类认知和组织活动结构的方式来设计和执行软件，从而简化修改和功能添加的难度。文章进一步阐述，典型的业务流程常常被手册化为工作流，而传统的业务系统是将这些工作流的元素（业务手册、业务系统、输入信息）分散实现的。BPOS则倡导将这三者统一为一个整体，具体表现为一个包含业务手册、输入信息字段以及下一环节负责人联系信息的文档。这个文档本身即是BPOS的应用，当被传递给相关人员时，即可驱动业务流程的执行。

作者强调，BPOS并非必须通过开发传统意义上的程序或系统来实现。该文件本身就可以作为“可执行软件”被人类执行，其中业务手册相当于人类执行的程序，输入字段则扮演数据存储的角色。更进一步，BPOS也可以成为人工智能（AI）的“可执行软件”。AI可以读取业务手册、理解任务，并自主执行部分任务或辅助人类执行。AI还可以根据人类的反馈调整交互方式，例如通过聊天界面、打开编辑器或生成临时应用程序来方便人类操作。完成任务后，AI可将文件传递给下一环节的负责人。

文章指出，文件格式应考虑AI的可处理性，Markdown格式被视为一个典型示例。BPOS通过允许组织直接创建或修改文件来添加或修改业务流程，无需开发程序，从而大大降低了流程改进的门槛。在业务手册中包含疑问或改进请求的联系点，有助于知识的集中和流程的持续改进。AI可以自动化或辅助这些知识的积累和流程的修改。这种模式使组织能够快速积累知识并持续自我改进，形成“快速学习型组织”。通过AI承担学习大量手册和适应流程变化的任务，人类只需通过简化的界面执行最少必要的工作，从而提高了组织的整体效率和适应性。</description>
</item>
<item>
  <title>框架设计作为一种智力能力</title>
  <link>https://katoshi-mfacet.github.io/zh/articles/2025/06_29_Framework-Design-Ability/</link>
  <guid>https://katoshi-mfacet.github.io/zh/articles/2025/06_29_Framework-Design-Ability/</guid>
  <pubDate>Sun, 29 Jun 2025 00:00:00 GMT</pubDate>
  <description>本文探讨了智力活动的不同轴线，核心在于区分“通过观察发现事实”与“通过设计发明物品和系统”这两种截然不同的智力活动。文章指出，学术活动主要以发现事实为中心，而开发则以发明创造为中心，两者在知识积累和应用上相互关联。然而，作者进一步强调，在学术领域内部也存在以设计为导向的智力活动，即“框架设计”。

框架设计被解释为创造新的概念框架，而非发现现有事实。文章以天文学中的地心说和日心说为例，说明它们并非关于事实的对错之争，而是关于选择哪种概念框架来解释观测事实，其价值判断基于实用性而非绝对正确性。牛顿力学、相对论和量子力学也被视为框架设计的范例，它们是根据不同情境的实用性而被区分使用的概念框架。作者认为，将这些称为“范式转换”不如称之为“范式发明”或“范式创新”更为贴切，因为它们增加了有用的选项，而非思维的彻底转变。

文章接着分析了这两种智力活动所需的技能组合差异。擅长通过观察进行发现的学者通常能在现有框架内获得认可，但并非所有学者都具备通过设计进行发明的技能，尤其是在学术领域内进行元级别的概念框架设计。

在此基础上，文章特别关注了软件工程师。作者认为，软件工程师在日常工作中，通过软件设计频繁地执行在元级别上重新配置抽象概念的任务，这使得他们潜在地拥有进行学术领域框架设计所需的技能组合。具备思考新设计模型的习惯的软件工程师，尤其适合将这种技能应用于高级的学术框架设计领域，通过设计发明新的抽象概念框架。</description>
</item>
</channel>
</rss>